{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RFCX_train_from_npy_image_v4_3_.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "t3l_5_WXkHrd"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ITzFStSplR82"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MMoGy2fAk8Sa"
      },
      "source": [
        "%%time\n",
        "# 大体10分くらい\n",
        "\n",
        "!pip install -q kaggle\n",
        "!mkdir -p .kaggle\n",
        "!cp \"./drive/My Drive/Study/config/kaggle.json\" .kaggle/\n",
        "!chmod 600 .kaggle/kaggle.json\n",
        "!mv .kaggle /root\n",
        "\n",
        "# image download\n",
        "!kaggle datasets download \"theoviel/rcfx-spectrograms-32-khz\"\n",
        "!unzip rcfx-spectrograms-32-khz.zip > /dev/null\n",
        "!rm -rf rcfx-spectrograms-32-khz.zip \n",
        "\n",
        "# Pseudo Labelings\n",
        "!kaggle datasets download \"aerdem4/rainforest-labelling\"\n",
        "!unzip rainforest-labelling.zip > /dev/null\n",
        "!rm -rf rainforest-labelling.zip \n",
        "!kaggle datasets download \"takamichitoda/rfcx-oof-pseudo-labeling\"\n",
        "!unzip rfcx-oof-pseudo-labeling.zip > /dev/null\n",
        "!rm -rf rfcx-oof-pseudo-labeling.zip \n",
        "!kaggle datasets download \"kuto0633/oof-efficientnet\"\n",
        "!unzip oof-efficientnet.zip > /dev/null\n",
        "!rm -rf oof-efficientnet.zip \n",
        "\n",
        "!pip install -U iterative-stratification albumentations wandb  > /dev/null\n",
        "!wandb login e0792bb688a0d18e359df7438c45da90f8794091\n",
        "\n",
        "!pip install timm\n",
        "!pip install imbalanced-learn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3zAeTPFiliqi"
      },
      "source": [
        "import gc\n",
        "import os\n",
        "import tqdm\n",
        "import random\n",
        "import pickle\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n",
        "from datetime import datetime\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from numpy.random import beta\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.optim import Adam, AdamW\n",
        "from torch.optim.lr_scheduler import CosineAnnealingLR, ReduceLROnPlateau, CosineAnnealingWarmRestarts\n",
        "from torchvision import transforms\n",
        "from torch.nn import functional as F\n",
        "\n",
        "import albumentations as A\n",
        "\n",
        "from sklearn.metrics import classification_report, roc_auc_score\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "import wandb\n",
        "import timm\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "device = torch.device(\"cuda\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V1qpv7F_Z-Mv"
      },
      "source": [
        "# Preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PE7WM-gFaDB4"
      },
      "source": [
        "## Set Constant Parameter"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jxC7lTYBzFFM"
      },
      "source": [
        "# timm.list_models(\"resnet*\")\n",
        "N_EXP = \"0214\"\n",
        "#MODEL_NAME = \"resnet18\"\n",
        "MODEL_NAME = \"efficientnet_b0\"\n",
        "#MODEL_NAME = \"densenet121\"\n",
        "#MODEL_NAME = \"resnest50d\"\n",
        "DETAIL = \"my_best\"  # gradient accumuration x mixup last layer\n",
        "STAGE = \"3rd\"  # 1st, 2nd, 3rd, 4th\n",
        "\n",
        "#BATCH_SZE = 64\n",
        "#BATCH_SZE = 32\n",
        "BATCH_SZE = 8\n",
        "#N_ACCUMULATE = 1\n",
        "N_ACCUMULATE = 4\n",
        "WINDOW = 512\n",
        "#WINDOW = 256\n",
        "\n",
        "SEED = 416\n",
        "N_FOLD = 5\n",
        "WORKS = 0\n",
        "N_LABEL = 24\n",
        "MAX_LEN = 3751\n",
        "\n",
        "EXP_NAME = f\"exp{N_EXP}_{MODEL_NAME}_{DETAIL}_{STAGE}\"\n",
        "OUTPUT = f\"./drive/MyDrive/Study/RFCX/output/{EXP_NAME}\"\n",
        "DATA_ROOT = \"./drive/MyDrive/Study/RFCX/input\"\n",
        "\n",
        "print(EXP_NAME)\n",
        "!mkdir -p {OUTPUT}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HCDqE-MXlkkz"
      },
      "source": [
        "# Pre-Train Model\n",
        "if MODEL_NAME == \"resnet18\":\n",
        "    FIRST_ST = \"exp0109_only_clip_loss\"\n",
        "elif MODEL_NAME == \"densenet121\":\n",
        "    FIRST_ST = \"exp0157_densenet121_for_ensemble_1st\"\n",
        "elif MODEL_NAME == \"resnest50d\":\n",
        "    FIRST_ST = \"exp0117_resnest_now_best\"\n",
        "elif MODEL_NAME == \"efficientnet_b0\":\n",
        "    FIRST_ST = \"exp0158_efficientnet_b0_for_ensemble_1st\"\n",
        "\n",
        "# Parameter\n",
        "if STAGE == \"1st\":\n",
        "    LEARNING_RATE = 1e-3\n",
        "    NUM_EPOCHS = 50\n",
        "    T_MAX = 10\n",
        "else:\n",
        "    LEARNING_RATE = 3e-4\n",
        "    NUM_EPOCHS = 5\n",
        "    T_MAX = 5\n",
        "\n",
        "if WINDOW == 256:\n",
        "    SHIFT_W = [0, 32, 64, 128]\n",
        "    COVER = 23\n",
        "    N_SPLIT_IMG = 16\n",
        "elif WINDOW == 512:\n",
        "    SHIFT_W = [0, 32, 64, 128, 256]\n",
        "    COVER = 49\n",
        "    N_SPLIT_IMG = 8"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9jrrgjgBVioc"
      },
      "source": [
        "slide_img_pos = [[0, WINDOW]]\n",
        "for idx in range(1, N_SPLIT_IMG):\n",
        "    h, t = slide_img_pos[idx-1][0], slide_img_pos[idx-1][1]\n",
        "    h = t - COVER\n",
        "    t = h + WINDOW\n",
        "    slide_img_pos.append([h, t])\n",
        "\n",
        "print(\"train slide_img_pos\")\n",
        "print(slide_img_pos)\n",
        "\n",
        "test_slide_img_pos = [[0, WINDOW]]\n",
        "for idx in range(1, 14):\n",
        "    h, t = test_slide_img_pos[idx-1][0], test_slide_img_pos[idx-1][1]\n",
        "    h = t - 256\n",
        "    t = h + WINDOW\n",
        "    test_slide_img_pos.append([h, t])\n",
        "\n",
        "print(\"test slide_img_pos\")\n",
        "print(test_slide_img_pos)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vf5dmlYmGIwT"
      },
      "source": [
        "## Load Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fYm7pa34Z0l-"
      },
      "source": [
        "# Competition Data\n",
        "sample_submission = pd.read_csv(f\"{DATA_ROOT}/sample_submission.csv\")\n",
        "train_fp = pd.read_csv(f\"{DATA_ROOT}/train_fp.csv\")\n",
        "train_tp = pd.read_csv(f\"{DATA_ROOT}/train_tp.csv\")\n",
        "\n",
        "# OOF Pseudo Labels\n",
        "oof_ahmet_v0 = pd.read_csv(\"oof_ahmet_v0.csv\")\n",
        "oof_toda_v1 = pd.read_csv(f\"./drive/MyDrive/Study/RFCX/OOF/oof_toda_v1.csv\")\n",
        "oof_kuto_v0 = pd.read_csv(\"oof_kuto_eff_v0.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4HRgn0P_W0CR"
      },
      "source": [
        "### Extract Label"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xi5WNCU3av6C"
      },
      "source": [
        "def _labeling(x):\n",
        "    if x < 0.01:\n",
        "        return -2  # difficult negative\n",
        "    elif x < 0.5:\n",
        "        return 0  # Don't know\n",
        "    return 2  # Pseudo Positive\n",
        "\n",
        "def _extract_seq_label(df):\n",
        "    seq_label = np.zeros((N_LABEL, 3751))\n",
        "    for species_id, t_min, f_min, t_max, f_max, type_value in df.values[:, [1, 3, 4, 5, 6, 7]]:\n",
        "        h, t = int(3751*(t_min/60)), int(3751*(t_max/60))\n",
        "        seq_label[species_id, h:t] = type_value\n",
        "    return seq_label\n",
        "\n",
        "def _put_soft_framewise_label(seq_label):\n",
        "    soft_framewise_label = []\n",
        "    for h, t in slide_img_pos:\n",
        "        _posi = ((seq_label[:, h:t] == 1).sum(1) > 0).astype(int)\n",
        "        _nega = ((seq_label[:, h:t] == -1).sum(1) > 0).astype(int)\n",
        "        if ((_posi + _nega) > 1).sum() > 0:\n",
        "            _nega = np.array([0 if _posi[i] == v == 1else v for i, v in enumerate(_nega)])\n",
        "        _lab = _posi + _nega*-1\n",
        "        soft_framewise_label.append(_lab)\n",
        "    soft_framewise_label = np.stack(soft_framewise_label)\n",
        "    return soft_framewise_label\n",
        "\n",
        "def _merge_pseudo_labels(org_label, pseudo_label):\n",
        "    lst = []\n",
        "    for l1, l2 in zip(org_label, pseudo_label):\n",
        "        org_zero_idx = np.where(l1 == 0)[0]\n",
        "        l1[org_zero_idx] = l2[org_zero_idx]\n",
        "        lst.append(l1)\n",
        "    return np.array(lst)\n",
        "\n",
        "def _merge_pseudo_labels_v2(org_label, pseudo_label):\n",
        "    lst = []\n",
        "    for l1, l2 in zip(org_label, pseudo_label):\n",
        "        org_zero_idx = np.where(l1 == 0)[0]\n",
        "        l1[org_zero_idx] = l2[org_zero_idx]\n",
        "        lst.append(l1)\n",
        "    return np.array(lst)\n",
        "\n",
        "train_tp[\"type_value\"] = 1  # Positive (TPs from data)\n",
        "train_fp[\"type_value\"] = -1  # False Positive (FP from the data)\n",
        "train_all = pd.concat([train_tp, train_fp], axis=0).reset_index(drop=True)\n",
        "\n",
        "new_label_dict = {}\n",
        "for recording_id, org_df in tqdm.notebook.tqdm(train_all.groupby(\"recording_id\"), total=len(train_all[\"recording_id\"].unique())):\n",
        "    # Pseudo Labels\n",
        "    pseudo1 = oof_ahmet_v0.query(f\"recording_id=='{recording_id}'\")\n",
        "    pseudo2 = oof_toda_v1.query(f\"recording_id=='{recording_id}'\")\n",
        "    pseudo3 = oof_kuto_v0.query(f\"recording_id=='{recording_id}'\")\n",
        "    pseudo_labels = np.stack([pseudo1.values[:, 2:],\n",
        "                               pseudo2.values[:, 2:],\n",
        "                               pseudo3.values[:, 2:]]).mean(0)\n",
        "    pseudo_labels = np.array([[_labeling(xx) for xx in x] for x in pseudo_labels])\n",
        "\n",
        "    # Origin Labels\n",
        "    seq_label = _extract_seq_label(org_df)\n",
        "    soft_framewise_label = _put_soft_framewise_label(seq_label)\n",
        "\n",
        "    # Merge Both Label\n",
        "    new_label = _merge_pseudo_labels(soft_framewise_label, pseudo_labels)\n",
        "    new_label_dict[recording_id] = new_label "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2PsEHW9H69yE"
      },
      "source": [
        "### Make CV"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gjS-8NLc7DFG"
      },
      "source": [
        "# 1st stage data\n",
        "tp_fnames, tp_labels = [], []\n",
        "for recording_id, df in train_tp.groupby(\"recording_id\"):\n",
        "    v = sum([np.eye(N_LABEL)[i] for i in df[\"species_id\"].tolist()])\n",
        "    v = (v  == 1).astype(int).tolist()\n",
        "    tp_fnames.append(recording_id)\n",
        "    tp_labels.append(v)\n",
        "\n",
        "# FP Data\n",
        "all_fnames = list(new_label_dict.keys())\n",
        "fp_only_fnames = [i for i in all_fnames if i not in tp_fnames]\n",
        "fp_positive_labels = [((new_label_dict[i] == 1).sum(0) > 0).astype(int) for i in fp_only_fnames]\n",
        "\n",
        "# Make CV\n",
        "mskf1 = MultilabelStratifiedKFold(n_splits=5, shuffle=True, random_state=0)\n",
        "tp_cv = [(np.array(tp_fnames)[train_index], np.array(tp_fnames)[valid_index]) for train_index, valid_index in mskf1.split(tp_fnames, tp_labels)]\n",
        "mskf２ = MultilabelStratifiedKFold(n_splits=5, shuffle=True, random_state=0)\n",
        "fp_cv = [(np.array(fp_only_fnames)[train_index], np.array(fp_only_fnames)[valid_index]) for train_index, valid_index in mskf2.split(fp_only_fnames, fp_positive_labels)]\n",
        "\n",
        "# origin label fixのため再計算\n",
        "tp_fnames, tp_labels = [], []\n",
        "for recording_id, df in train_tp.groupby(\"recording_id\"):\n",
        "    v = sum([np.eye(N_LABEL)[i] for i in df[\"species_id\"].tolist()])\n",
        "    v = (v  >= 1).astype(int).tolist()  # fix\n",
        "    tp_fnames.append(recording_id)\n",
        "    tp_labels.append(v)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RKong_NrMIEM"
      },
      "source": [
        "## Functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HLeV-M8oGLir"
      },
      "source": [
        "### Utils"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kv4tt5lLl03a"
      },
      "source": [
        "# https://www.kaggle.com/c/rfcx-species-audio-detection/discussion/198418\n",
        "\n",
        "def LWLRAP(preds, labels):\n",
        "    ranked_classes = torch.argsort(preds, dim=-1, descending=True)\n",
        "    class_ranks = torch.zeros_like(ranked_classes)\n",
        "    for i in range(ranked_classes.size(0)):\n",
        "        for j in range(ranked_classes.size(1)):\n",
        "            class_ranks[i, ranked_classes[i][j]] = j + 1\n",
        "    ground_truth_ranks = class_ranks * labels + (1e6) * (1 - labels)\n",
        "    sorted_ground_truth_ranks, _ = torch.sort(ground_truth_ranks, dim=-1, descending=False)\n",
        "    num_labels = labels.sum(-1)\n",
        "    pos_matrix = torch.tensor(np.array([i+1 for i in range(labels.size(-1))])).unsqueeze(0)\n",
        "    score_matrix = pos_matrix / sorted_ground_truth_ranks\n",
        "    score_mask_matrix, _ = torch.sort(labels, dim=-1, descending=True)\n",
        "    scores = score_matrix * score_mask_matrix\n",
        "    score = scores.sum() / labels.sum()\n",
        "    return score.item()\n",
        "\n",
        "def set_seed(seed: int = 42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)  # type: ignore\n",
        "    torch.backends.cudnn.deterministic = True  # type: ignore\n",
        "    torch.backends.cudnn.benchmark = True  # type: ignore"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fwL1_s3YW_ga"
      },
      "source": [
        "### DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZzKRUeO9lqA4"
      },
      "source": [
        "class TimeMask:\n",
        "    def __init__(self, T=40, num_masks=1, replace_with_zero=True):\n",
        "        self.T = T\n",
        "        self.num_masks = num_masks\n",
        "        self.replace_with_zero = replace_with_zero\n",
        "\n",
        "    def __call__(self, spec):\n",
        "        cloned = spec.clone()\n",
        "        len_spectro = cloned.shape[2]\n",
        "    \n",
        "        for i in range(0, self.num_masks):\n",
        "            t = random.randrange(0, self.T)\n",
        "            t_zero = random.randrange(0, len_spectro - t)\n",
        "\n",
        "            # avoids randrange error if values are equal and range is empty\n",
        "            if (t_zero == t_zero + t): return cloned\n",
        "\n",
        "            mask_end = random.randrange(t_zero, t_zero + t)\n",
        "            if (self.replace_with_zero): cloned[:,:,t_zero:mask_end] = 0\n",
        "            else: cloned[:,:,t_zero:mask_end] = cloned.mean()\n",
        "        return cloned\n",
        "\n",
        "class FreqMask:\n",
        "    def __init__(self, F=30, num_masks=1, replace_with_zero=True):\n",
        "        self.F = F\n",
        "        self.num_masks = num_masks\n",
        "        self.replace_with_zero = replace_with_zero\n",
        "\n",
        "    def __call__(self, spec):\n",
        "        cloned = spec.clone()\n",
        "        num_mel_channels = cloned.shape[1]\n",
        "    \n",
        "        for i in range(0, self.num_masks):        \n",
        "            f = random.randrange(0, self.F)\n",
        "            f_zero = random.randrange(0, num_mel_channels - f)\n",
        "\n",
        "            # avoids randrange error if values are equal and range is empty\n",
        "            if (f_zero == f_zero + f): return cloned\n",
        "\n",
        "            mask_end = random.randrange(f_zero, f_zero + f) \n",
        "            if (self.replace_with_zero): cloned[:, f_zero:mask_end] = 0\n",
        "            else: cloned[:, f_zero:mask_end] = cloned.mean()\n",
        "    \n",
        "        return cloned\n",
        "\n",
        "def mono_to_color(\n",
        "    X: np.ndarray, mean=None, std=None,\n",
        "    norm_max=None, norm_min=None, eps=1e-6\n",
        "):\n",
        "    # Stack X as [X,X,X]\n",
        "    X = np.stack([X, X, X], axis=-1)\n",
        "\n",
        "    # Standardize\n",
        "    mean = mean or X.mean()\n",
        "    X = X - mean\n",
        "    std = std or X.std()\n",
        "    Xstd = X / (std + eps)\n",
        "    _min, _max = Xstd.min(), Xstd.max()\n",
        "    norm_max = norm_max or _max\n",
        "    norm_min = norm_min or _min\n",
        "    if (_max - _min) > eps:\n",
        "        # Normalize to [0, 255]\n",
        "        V = Xstd\n",
        "        V[V < norm_min] = norm_min\n",
        "        V[V > norm_max] = norm_max\n",
        "        V = 255 * (V - norm_min) / (norm_max - norm_min)\n",
        "        V = V.astype(np.uint8)\n",
        "    else:\n",
        "        # Just zero\n",
        "        V = np.zeros_like(Xstd, dtype=np.uint8)\n",
        "    return V\n",
        "\n",
        "\n",
        "class SpectrogramFromNpz(torch.utils.data.Dataset):\n",
        "    def __init__(self, fname, mode):\n",
        "        self.fname = fname\n",
        "        self.mode = mode\n",
        "        self.to_tensor = transforms.ToTensor()\n",
        "        self.norm = transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
        "        self.augument_funcs_b = transforms.RandomApply([\n",
        "            TimeMask(),\n",
        "            FreqMask(),\n",
        "        ], p=0.5)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.fname)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        fname = self.fname[idx]\n",
        "\n",
        "        # load label\n",
        "        if self.mode in [\"train\", \"valid\"]:\n",
        "            label = new_label_dict[fname]\n",
        "            img_dir = \"train\"\n",
        "        elif self.mode == \"test\":\n",
        "            label = np.zeros(((N_SPLIT_IMG, N_LABEL)))\n",
        "            img_dir = \"test\"\n",
        "\n",
        "        # load image        \n",
        "        path = f\"./{img_dir}/{fname}.npy\"\n",
        "        mel = np.load(path)\n",
        "        image = mono_to_color(mel)\n",
        "\n",
        "        # augument\n",
        "        if self.mode == \"train\":\n",
        "            image = self.to_tensor(image)\n",
        "            image = self.augument_funcs_b(image)\n",
        "        elif self.mode in [\"valid\", \"test\"]:\n",
        "            image = self.to_tensor(image)\n",
        "        image = self.norm(image)\n",
        "\n",
        "        return image, label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TG2sqskrMPxh"
      },
      "source": [
        "#_datasets = SpectrogramFromNpz(all_fnames[:2], \"train\")\n",
        "#for d in _datasets:\n",
        "   #break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lrKEIKi0KD-8"
      },
      "source": [
        "### Main Loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nDWcvxkKl70K"
      },
      "source": [
        "def mixup(input, gamma, perm):\n",
        "    perm_input = input[perm]\n",
        "    return input.mul_(gamma).add_(1 - gamma, perm_input)\n",
        "\n",
        "def rfcx_3rd_criterion(outputs, targets, b=None, perm=None):\n",
        "    clipwise_preds_att_ti = outputs[\"clipwise_preds_att_ti\"]\n",
        "\n",
        "    posi_label = (targets == 1).float().to(device)\n",
        "    nega_label = (targets == -1).float().to(device)\n",
        "    soft_posi_label = (targets == 2).float().to(device)\n",
        "    posi_y = torch.ones(clipwise_preds_att_ti.shape).to(device)\n",
        "    nega_y = torch.zeros(clipwise_preds_att_ti.shape).to(device)\n",
        "\n",
        "    # mixup treat\n",
        "    posi_label = mixup(posi_label, b, perm)\n",
        "    soft_posi_label = mixup(soft_posi_label, b, perm)\n",
        " \n",
        "    posi_loss = nn.BCEWithLogitsLoss(reduction=\"none\")(clipwise_preds_att_ti, posi_y)\n",
        "    nega_loss = nn.BCEWithLogitsLoss(reduction=\"none\")(clipwise_preds_att_ti, nega_y)\n",
        "    soft_posi_loss = nn.BCEWithLogitsLoss(reduction=\"none\")(clipwise_preds_att_ti, posi_y)\n",
        "\n",
        "    posi_loss = (posi_loss * posi_label).sum()\n",
        "    nega_loss = (nega_loss * nega_label).sum()\n",
        "    soft_posi_loss = (soft_posi_loss * soft_posi_label).sum()\n",
        "\n",
        "    loss = posi_loss + nega_loss + soft_posi_loss*0.5\n",
        "\n",
        "    return loss\n",
        "\n",
        "def split_and_padding(X, y):\n",
        "    X_lst, y_lst =[], []\n",
        "    for idx, (h, t) in enumerate(slide_img_pos):\n",
        "        _X = X[:, :, :, h:t]\n",
        "        _y = y[:, idx, :]\n",
        "        if _X.shape[3] != WINDOW:\n",
        "            x_pad = torch.zeros(list(_X.shape[:-1]) + [WINDOW - _X.shape[3]])\n",
        "            _X = torch.cat([_X, x_pad], axis=3)\n",
        "        X_lst.append(_X)\n",
        "        y_lst.append(_y)\n",
        "    X = torch.cat(X_lst, axis=0)\n",
        "    y = torch.cat(y_lst, axis=0)\n",
        "    return X, y\n",
        "\n",
        "def split_and_padding_test(X):\n",
        "    X_lst =[]\n",
        "    for idx, (h, t) in enumerate(test_slide_img_pos):\n",
        "        _X = X[:, :, :, h:t]\n",
        "        if _X.shape[3] != WINDOW:\n",
        "            x_pad = torch.zeros(list(_X.shape[:-1]) + [WINDOW - _X.shape[3]])\n",
        "            _X = torch.cat([_X, x_pad], axis=3)\n",
        "        X_lst.append(_X)\n",
        "    X = torch.cat(X_lst, axis=0)\n",
        "    return X\n",
        "\n",
        "def train_loop_3rd(train_data_loader, model, optimizer, scheduler):\n",
        "    model.train()\n",
        "    losses, lrs = [], []\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    for n_iter, (X, y) in tqdm.notebook.tqdm(enumerate(train_data_loader), total=len(train_data_loader)):\n",
        "        _X, _y = split_and_padding(X, y)\n",
        "        _X, _y = _X.to(device), _y.to(device)\n",
        "\n",
        "        b = beta(0.1, 0.1)\n",
        "        perm = torch.randperm(_X.size(0))\n",
        "        outputs = model(_X, perm, b)\n",
        "        loss = rfcx_criterion(outputs, _y, b, perm)\n",
        "\n",
        "        loss.backward()\n",
        "        if n_iter % N_ACCUMULATE == 0:\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "        if scheduler is not None:\n",
        "            scheduler.step()\n",
        "\n",
        "        losses.append(loss.item())\n",
        "        lrs.append(np.array([param_group[\"lr\"] for param_group in optimizer.param_groups]).mean())\n",
        "    t_loss = np.array(losses).mean()\n",
        "    lr =  np.array(lrs).mean()\n",
        "    return t_loss, lr\n",
        "    \n",
        "\n",
        "def predict(data_loader, model):\n",
        "    model.eval()\n",
        "    clip_preds, clip_targets = [], []\n",
        "    for X, y in valid_data_loader:\n",
        "        clip_y = ((y >=1).sum(1) > 0).int().numpy()\n",
        "        _X = split_and_padding_test(X)\n",
        "        _X = _X.to(device)\n",
        "        with torch.no_grad():\n",
        "            outputs = model(_X)\n",
        "        segmentwise_output_ti = outputs[\"segmentwise_output_ti\"].sigmoid().cpu().numpy()\n",
        "\n",
        "        org_shape = (len(test_slide_img_pos), y.shape[0], N_LABEL, WINDOW)\n",
        "        _segmentwise_output_ti = segmentwise_output_ti.reshape(org_shape)\n",
        "        _clip_pred = _segmentwise_output_ti.max(0).max(2)\n",
        "\n",
        "        clip_preds.append(_clip_pred)\n",
        "        clip_targets.append(clip_y)\n",
        "\n",
        "    clip_preds = np.vstack(clip_preds)\n",
        "    clip_targets = np.vstack(clip_targets)\n",
        "\n",
        "    return clip_preds, clip_targets\n",
        "\n",
        "\n",
        "def valid_loop_3rd(valid_data_loader, model, n_origin_tp_valid):\n",
        "    clip_preds, clip_targets = predict(valid_data_loader, model)\n",
        "    \n",
        "    res_d = {}\n",
        "    # 3rd Stage\n",
        "    res_d[\"lwlrap\"] = LWLRAP(torch.tensor(clip_preds), torch.tensor(clip_targets))\n",
        "    res_d[\"valid_loss\"] = nn.BCEWithLogitsLoss()(torch.tensor(clip_preds), torch.tensor(clip_targets).float()).numpy()\n",
        "    lst = []\n",
        "    for _true_y, _pred_y in zip(clip_targets.T, clip_preds.T):\n",
        "        res = classification_report(_true_y.astype(int), (_pred_y > 0.5).astype(int), output_dict=True)\n",
        "        res = res[\"1\"]\n",
        "        res[\"auc\"] = roc_auc_score(_true_y, _pred_y)\n",
        "        lst.append(res)\n",
        "    res_df = pd.DataFrame(lst)\n",
        "    res_d[\"precision\"] = res_df.mean()[\"precision\"]\n",
        "    res_d[\"recall\"] = res_df.mean()[\"recall\"]\n",
        "    res_d[\"auc\"] = res_df.mean()[\"auc\"]\n",
        "\n",
        "    # Origin\n",
        "    res_d[\"org_lwlrap\"] = LWLRAP(torch.tensor(clip_preds[:n_origin_tp_valid]), torch.tensor(org_tp_labels))\n",
        "    res_d[\"org_valid_loss\"] = nn.BCEWithLogitsLoss()(torch.tensor(clip_preds[:n_origin_tp_valid]), torch.tensor(org_tp_labels).float()).numpy()\n",
        "    lst = []\n",
        "    for _true_y, _pred_y in zip(org_tp_labels.T, clip_preds[:n_origin_tp_valid].T):\n",
        "        res = classification_report(_true_y.astype(int), (_pred_y > 0.5).astype(int), output_dict=True)\n",
        "        res = res[\"1\"]\n",
        "        res[\"auc\"] = roc_auc_score(_true_y, _pred_y)\n",
        "        lst.append(res)\n",
        "    res_df = pd.DataFrame(lst)\n",
        "    res_d[\"org_precision\"] = res_df.mean()[\"precision\"]\n",
        "    res_d[\"org_recall\"] = res_df.mean()[\"recall\"]\n",
        "    res_d[\"org_auc\"] = res_df.mean()[\"auc\"]\n",
        "\n",
        "    return res_d"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DLMnu5R7KIfh"
      },
      "source": [
        "### Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zhKxRdYVMQb-"
      },
      "source": [
        "# ヘッダーのインデックスと次元数\n",
        "MODEL_HEADER_INFO = {\n",
        "    \"resnet18\": (-2, 512),\n",
        "    \"densenet121\": (-2, 1024),\n",
        "    \"efficientnet_b0\": (-5, 320),\n",
        "    \"resnest50d\": (-2, 2048),\n",
        "    \"mobilenetv2_100\": (-2, 1280),\n",
        "}\n",
        "\n",
        "def interpolate(x: torch.Tensor, ratio: int):\n",
        "    x = x.transpose(1, 2)\n",
        "    (batch_size, time_steps, classes_num) = x.shape\n",
        "    upsampled = x[:, :, None, :].repeat(1, 1, ratio, 1)\n",
        "    upsampled = upsampled.reshape(batch_size, time_steps * ratio, classes_num)\n",
        "    upsampled = upsampled.transpose(1, 2)\n",
        "    return upsampled\n",
        "\n",
        "\n",
        "class RFCXNet(nn.Module):\n",
        "    def __init__(self, model_name):\n",
        "        super(RFCXNet, self).__init__()\n",
        "        self.model_name = model_name\n",
        "        self.n_label = N_LABEL\n",
        "\n",
        "        base_model = timm.create_model(model_name, pretrained=True)\n",
        "        h_idx, n_dense = MODEL_HEADER_INFO[model_name]        \n",
        "\n",
        "        # 過去学習に使ったモデルをロードするためヘッダーの名前を変える\n",
        "        if self.model_name in [\"resnet18\", \"efficientnet_b0\"]:\n",
        "            self.resnet_head = nn.Sequential(*list(base_model.children())[:h_idx])\n",
        "        elif self.model_name == \"resnest50d\":\n",
        "            self.resnest50d_head = nn.Sequential(*list(base_model.children())[:h_idx])\n",
        "        else:\n",
        "            self.model_head = nn.Sequential(*list(base_model.children())[:h_idx])\n",
        "                \n",
        "\n",
        "        self.fc_a = nn.Conv1d(n_dense, self.n_label, 1, bias=False)\n",
        "        self.fc_b = nn.Conv1d(n_dense, self.n_label, 1, bias=False)\n",
        "\n",
        "    def forward(self, x, perm=None, gamma=None):  # input x: (batch, channel, Hz, time)\n",
        "        frames_num = x.shape[3]\n",
        "        x = x.transpose(3, 2)  # (batch, channel, time, Hz)\n",
        "\n",
        "        # (batch, unit, time, Hz)\n",
        "        if self.model_name in [\"resnet18\", \"efficientnet_b0\"]:\n",
        "            h = self.resnet_head(x)  \n",
        "        elif self.model_name == \"resnest50d\":\n",
        "            h = self.resnest50d_head(x)\n",
        "        else:\n",
        "            h = self.model_head(x)\n",
        "        \n",
        "        if perm is not None:\n",
        "            h = gamma * h + (1 - gamma) * h[perm]\n",
        "    \n",
        "        h = F.relu(h)\n",
        "        ti_pool = torch.mean(h, dim=3)  # (batch, unit, time)\n",
        "\n",
        "        xa = self.fc_a(ti_pool)  # (batch, n_class, time)\n",
        "        xb = self.fc_b(ti_pool)  # (batch, n_class, time)\n",
        "        xb = torch.softmax(xb, dim=2)\n",
        "\n",
        "        # time pool\n",
        "        clipwise_preds_att_ti = torch.sum(xa * xb, dim=2)\n",
        "        segmentwise_output_ti = interpolate(xa, 32)\n",
        "\n",
        "        return {\n",
        "            \"clipwise_preds_att_ti\": clipwise_preds_att_ti,\n",
        "            \"segmentwise_output_ti\": segmentwise_output_ti,\n",
        "        }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u7CpykTZPChS"
      },
      "source": [
        "\"\"\"train_datasets = SpectrogramFromNpz(all_fnames, \"train\")\n",
        "train_data_loader = torch.utils.data.DataLoader(train_datasets, batch_size=2, shuffle=True, num_workers=0)\n",
        "for n_iter, (X, y) in tqdm.tqdm_notebook(enumerate(train_data_loader)):\n",
        "    _X, _y = split_and_padding(X, y)\n",
        "    break\n",
        "model = RFCXNet(\"resnet18\")\n",
        "model.to(device)\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    outputs = model(_X.to(device))\n",
        "outputs[\"segmentwise_output_ti\"].shape\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JLOXyiMEO3cI"
      },
      "source": [
        "## Test Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jIkq_ryBO2Ck"
      },
      "source": [
        "test_fnames = sample_submission[\"recording_id\"].values\n",
        "test_datasets = SpectrogramFromNpz(test_fnames, \"test\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xzKg3IwYzKiH"
      },
      "source": [
        "# Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LzM8bj6PWfXm"
      },
      "source": [
        "for fold in range(5):\n",
        "    #if fold in [0,1,2]:  # Set Skip Fold\n",
        "    #    continue\n",
        "    print(datetime.now(), f\"\\t: ### FOLD-{fold} ###\")\n",
        "    set_seed(SEED+fold)\n",
        "\n",
        "    wandb.init(project=\"rfcx\", name=f\"{EXP_NAME}_f{fold}\")\n",
        "\n",
        "    config = wandb.config\n",
        "    config.exp_name = EXP_NAME\n",
        "    config.fold = fold\n",
        "    config.seed = SEED\n",
        "    config.learning_rate = LEARNING_RATE\n",
        "    config.batch_size = BATCH_SZE\n",
        "    config.num_epochs = NUM_EPOCHS\n",
        "    config.t_max = T_MAX\n",
        "    config.n_accumulate = N_ACCUMULATE\n",
        "\n",
        "    tp_train, tp_valid = tp_cv[fold]\n",
        "    fp_train, fp_valid = fp_cv[fold]\n",
        "    train_fname = np.hstack([tp_train, fp_train])\n",
        "    valid_fname = np.hstack([tp_valid, fp_valid])\n",
        "    n_origin_tp_valid = len(tp_valid)\n",
        "    org_tp_labels = np.array(tp_labels)[[tp_fnames.index(i) for i in tp_valid]]\n",
        "    \n",
        "    if STAGE == \"3rd\":\n",
        "        rfcx_criterion = rfcx_3rd_criterion\n",
        "        train_loop = train_loop_3rd\n",
        "        valid_loop = valid_loop_3rd\n",
        "\n",
        "    train_datasets = SpectrogramFromNpz(train_fname, \"train\")  \n",
        "    train_data_loader = torch.utils.data.DataLoader(train_datasets, batch_size=config.batch_size, shuffle=True, num_workers=WORKS)\n",
        "    valid_datasets = SpectrogramFromNpz(valid_fname, \"valid\")\n",
        "    valid_data_loader = torch.utils.data.DataLoader(valid_datasets, batch_size=config.batch_size, shuffle=False, num_workers=WORKS)\n",
        "\n",
        "    model = RFCXNet(MODEL_NAME)\n",
        "    if STAGE in [\"2nd\", \"3rd\"]:\n",
        "        model.load_state_dict(torch.load(f\"./drive/MyDrive/Study/RFCX/output/{FIRST_ST}/rfcxnet_f{config.fold}_best_score_model.bin\"))\n",
        "    model.to(device)\n",
        "\n",
        "    optimizer = Adam(model.parameters(), lr=config.learning_rate)\n",
        "    scheduler = CosineAnnealingLR(optimizer, T_max=len(train_data_loader)*config.t_max, eta_min=0.0)\n",
        "\n",
        "    wandb.watch(model)\n",
        "\n",
        "    print(datetime.now(), \"\\t: start train\")\n",
        "    best_lwlrap, best_precision, best_auc, best_recall = 0, 0, 0, 0\n",
        "    for epoch in range(config.num_epochs):\n",
        "        t_loss, lr = train_loop(train_data_loader, model, optimizer, scheduler)\n",
        "        valid_d = valid_loop(valid_data_loader, model, n_origin_tp_valid)\n",
        "\n",
        "        if best_lwlrap < valid_d[\"lwlrap\"]:\n",
        "            print(f\"epoch {epoch}: best score update !!!\")\n",
        "            torch.save(model.state_dict(), f\"{OUTPUT}/rfcxnet_f{config.fold}_best_score_model.bin\")\n",
        "            best_lwlrap = valid_d[\"lwlrap\"]\n",
        "            best_precision = valid_d[\"precision\"]\n",
        "            best_auc = valid_d[\"auc\"]\n",
        "            best_recall = valid_d[\"recall\"]\n",
        "\n",
        "        valid_d[\"best_lwlrap\"] = best_lwlrap\n",
        "        valid_d[\"best_precision\"] = best_precision\n",
        "        valid_d[\"best_auc\"] = best_auc\n",
        "        valid_d[\"best_recall\"] = best_recall\n",
        "        valid_d[\"train_loss\"] = t_loss\n",
        "        valid_d[\"lr\"] = lr\n",
        "        wandb.log(valid_d)\n",
        "\n",
        "    print(datetime.now(), \"\\t: finish train\")\n",
        "    wandb.finish()\n",
        "\n",
        "    # predict test data\n",
        "    model.load_state_dict(torch.load(f\"{OUTPUT}/rfcxnet_f{config.fold}_best_score_model.bin\"))\n",
        "    model.eval()\n",
        "\n",
        "    lst = []\n",
        "    for idx, (X, _) in tqdm.tqdm_notebook(enumerate(test_datasets), total=1992):\n",
        "        preds = []\n",
        "        for h, t in test_slide_img_pos:\n",
        "            _X = X[:,:,h:t].unsqueeze(0)\n",
        "            if _X.shape[3] != WINDOW:\n",
        "                x_pad = torch.zeros(list(_X.shape[:-1]) + [WINDOW - _X.shape[3]])\n",
        "                _X = torch.cat([_X, x_pad], axis=3)\n",
        "            with torch.no_grad():\n",
        "                outputs = model(_X.to(device))\n",
        "            pred, _ = outputs[\"segmentwise_output_ti\"].sigmoid().max(2)\n",
        "            preds.append(pred)\n",
        "        max_pred, _  = torch.max(torch.stack(preds), dim=0)\n",
        "        pred = max_pred.cpu().numpy()[0].tolist()\n",
        "\n",
        "        row = [test_fnames[idx]] + pred\n",
        "        lst.append(row)\n",
        "\n",
        "    fold_sub = pd.DataFrame(lst, columns=[\"recording_id\"]+[f\"s{i}\" for i in range(N_LABEL)])\n",
        "    fold_sub.to_csv(f\"{OUTPUT}/rfcxnet_f{config.fold}_predict.csv\", index=None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "txMDjtk8cNGv"
      },
      "source": [
        "# Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bOR0_hcSoVC_"
      },
      "source": [
        "all_v_lst = []\n",
        "for fold in range(5):\n",
        "    df = pd.read_csv(f\"{OUTPUT}/rfcxnet_f{fold}_predict.csv\")\n",
        "    ids, v_lst = [], []\n",
        "    for row in df.values:\n",
        "        recording_id = row[0]\n",
        "        ids.append(recording_id)\n",
        "        v = torch.Tensor(row[1:].astype(float))\n",
        "        v_lst.append(v)\n",
        "    all_v_lst.append(torch.stack(v_lst, axis=0))\n",
        "\n",
        "all_preds = torch.stack(all_v_lst, axis=2).mean(2)\n",
        "sub = pd.DataFrame(all_preds.tolist(), columns=df.columns[1:])\n",
        "sub = pd.concat([df[[\"recording_id\"]], sub], axis=1)\n",
        "sub.to_csv(f\"./submission_{EXP_NAME}_avg.csv\", index=None)\n",
        "\n",
        "!cp \"./submission_{EXP_NAME}_avg.csv\" \"{OUTPUT}\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w-OZOmYN-5i8"
      },
      "source": [
        "# Pseudo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1w5VjZgBE4Iu"
      },
      "source": [
        "pseudo_version = 7\n",
        "#MODEL_NAME = \"resnet18\"\n",
        "#OUTPUT = \"./drive/MyDrive/Study/RFCX/output/exp0211_resnet18_mixup_posilab_3rd\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5-mkKS54wJXe"
      },
      "source": [
        "## OOF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9wFm1wak9-QD"
      },
      "source": [
        "model = RFCXNet(MODEL_NAME)\n",
        "model.to(device)\n",
        "\n",
        "valid_dfs = []\n",
        "for fold in range(5):\n",
        "    print(datetime.now(), f\"\\t: ### FOLD-{fold} ###\")\n",
        "    set_seed(SEED+fold)\n",
        "\n",
        "    tp_train, tp_valid = tp_cv[fold]\n",
        "    fp_train, fp_valid = fp_cv[fold]\n",
        "    valid_fname = np.hstack([tp_valid, fp_valid])\n",
        "\n",
        "    valid_datasets = SpectrogramFromNpz(valid_fname, \"valid\")\n",
        "    model.load_state_dict(torch.load(f\"{OUTPUT}/rfcxnet_f{fold}_best_score_model.bin\"))\n",
        "    model.eval()\n",
        "\n",
        "    clip_targets_org, clip_targets_new, valid_preds = [], [], []\n",
        "    for idx, (X, y) in tqdm.notebook.tqdm(enumerate(valid_datasets), total=len(valid_datasets)):\n",
        "        clip_y_org = ((y == 1).sum(0) > 0).astype(int)\n",
        "        clip_y_new = ((y >= 1).sum(0) > 0).astype(int)\n",
        "        clip_targets_org.append(clip_y_org)\n",
        "        clip_targets_new.append(clip_y_new)\n",
        "\n",
        "        for patch, (h, t) in enumerate(test_slide_img_pos):\n",
        "        #for patch, (h, t) in enumerate(slide_img_pos):\n",
        "            _X = X[:,:,h:t].unsqueeze(0)\n",
        "            if _X.shape[3] != WINDOW:\n",
        "                x_pad = torch.zeros(list(_X.shape[:-1]) + [WINDOW - _X.shape[3]])\n",
        "                _X = torch.cat([_X, x_pad], axis=3)\n",
        "            with torch.no_grad():\n",
        "                outputs = model(_X.to(device))\n",
        "            pred, _ = outputs[\"segmentwise_output_ti\"].sigmoid().max(2)\n",
        "            row = [valid_fname[idx], patch] + pred.cpu().tolist()[0]\n",
        "            valid_preds.append(row)\n",
        "        \n",
        "    valid_df = pd.DataFrame(valid_preds, columns=[\"recording_id\", \"patch\"] + [f\"s{i}\" for i in range(24)])\n",
        "    valid_dfs.append(valid_df)\n",
        "\n",
        "    clip_targets_org = np.stack(clip_targets_org)\n",
        "    clip_targets_new = np.stack(clip_targets_new)\n",
        "    clip_preds = valid_df.groupby(\"recording_id\").max().drop(\"patch\", axis=1).loc[valid_fname].values\n",
        "    lwlrap_org = LWLRAP(torch.tensor(clip_preds), torch.tensor(clip_targets_org))\n",
        "    lwlrap_new = LWLRAP(torch.tensor(clip_preds), torch.tensor(clip_targets_new))\n",
        "    print(f\"LWLRAP] org={lwlrap_org}, new={lwlrap_new}\")\n",
        "oof_pseudo = pd.concat(valid_dfs).reset_index(drop=True)\n",
        "oof_pseudo.to_csv(f\"oof_toda_v{pseudo_version}.csv\", index=None)\n",
        "\n",
        "!cp oof_toda_v{pseudo_version}.csv ./drive/MyDrive/Study/RFCX/OOF/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aM9rUmGMwKyw"
      },
      "source": [
        "## Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "de-g-TBQpqT7"
      },
      "source": [
        "model = RFCXNet(MODEL_NAME)\n",
        "model.to(device)\n",
        "\n",
        "test_preds_dfs = []\n",
        "for fold in range(5):\n",
        "    print(datetime.now(), f\"\\t: ### FOLD-{fold} ###\")\n",
        "    set_seed(SEED+fold)\n",
        "    model.load_state_dict(torch.load(f\"{OUTPUT}/rfcxnet_f{fold}_best_score_model.bin\"))\n",
        "    model.eval()\n",
        "\n",
        "    test_preds = []\n",
        "    for idx, (X, _) in tqdm.notebook.tqdm(enumerate(test_datasets), total=1992):\n",
        "        for patch, (h, t) in enumerate(test_slide_img_pos):\n",
        "        #for patch, (h, t) in enumerate(slide_img_pos):\n",
        "            _X = X[:,:,h:t].unsqueeze(0)\n",
        "            if _X.shape[3] != WINDOW:\n",
        "                x_pad = torch.zeros(list(_X.shape[:-1]) + [WINDOW - _X.shape[3]])\n",
        "                _X = torch.cat([_X, x_pad], axis=3)\n",
        "            with torch.no_grad():\n",
        "                outputs = model(_X.to(device))\n",
        "            pred, _ = outputs[\"segmentwise_output_ti\"].sigmoid().max(2)\n",
        "            row = [test_datasets.fname[idx], patch] + pred.cpu().tolist()[0]\n",
        "            test_preds.append(row)\n",
        "    test_preds_df = pd.DataFrame(test_preds, columns=[\"recording_id\", \"patch\"] + [f\"s{i}\" for i in range(24)])\n",
        "    test_preds_dfs.append(test_preds_df)\n",
        "\n",
        "lst = []\n",
        "for fold in range(5):\n",
        "    v = test_preds_dfs[fold].values[:, 2:]\n",
        "    lst.append(v)\n",
        "pred_v = np.array(lst)\n",
        "pd.DataFrame(np.hstack([test_preds_dfs[0].values[:, :2], pred_v.mean(0)]),\n",
        "                         columns=test_preds_df.columns).to_csv(f\"test_toda_v{pseudo_version}.csv\", index=None)\n",
        "\n",
        "!cp test_toda_v{pseudo_version}.csv ./drive/MyDrive/Study/RFCX/OOF/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7CjdM7I0sAUD"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}