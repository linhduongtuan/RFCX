{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RFCX train from npy image v1.0 .ipynb",
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M8PMd5lMlCog"
      },
      "source": [
        "# RFCX"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0uKx9rcFlGn8"
      },
      "source": [
        "## 準備"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lxEpVyQFulmr"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c_gcK0C7bMIF"
      },
      "source": [
        "%%time\n",
        "\n",
        "!pip install -q kaggle\n",
        "!mkdir -p .kaggle\n",
        "!cp \"./drive/My Drive/Study/config/kaggle.json\" .kaggle/\n",
        "!chmod 600 .kaggle/kaggle.json\n",
        "!mv .kaggle /root\n",
        "\n",
        "!kaggle datasets download \"theoviel/rcfx-spectrograms-32-khz\"\n",
        "!unzip rcfx-spectrograms-32-khz.zip > /dev/null\n",
        "!rm -rf rcfx-spectrograms-32-khz.zip "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "APVBPPrtfr7b"
      },
      "source": [
        "!pip install iterative-stratification"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jQUtLCffsJeR"
      },
      "source": [
        "!pip install --upgrade wandb\n",
        "!wandb login e0792bb688a0d18e359df7438c45da90f8794091"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BKofjv7SlKC1"
      },
      "source": [
        "## 実行コード"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t_2A8YCLlOzu"
      },
      "source": [
        "### ライブラリとデータの読み込み"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4hcKKbx-cky2"
      },
      "source": [
        "import os\n",
        "import tqdm\n",
        "import random\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from numpy.random import beta\n",
        "\n",
        "import torch\n",
        "from torchvision.models import resnet18\n",
        "import torch.nn as nn\n",
        "from torch.optim import Adam\n",
        "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
        "from torchvision import transforms\n",
        "from torch.nn import functional as F\n",
        "\n",
        "import wandb\n",
        "\n",
        "device = torch.device(\"cuda\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rfyo-ZoLcS4Z"
      },
      "source": [
        "DATA_ROOT = \"./drive/MyDrive/Study/RFCX/input\"\n",
        "\n",
        "sample_submission = pd.read_csv(f\"{DATA_ROOT}/sample_submission.csv\")\n",
        "train_fp = pd.read_csv(f\"{DATA_ROOT}/train_fp.csv\")\n",
        "train_tp = pd.read_csv(f\"{DATA_ROOT}/train_tp.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fMTETaz7lVFj"
      },
      "source": [
        "### 関数群"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Igops5Secsj0"
      },
      "source": [
        "label_dict = {}\n",
        "for recording_id, df in train_tp.groupby(\"recording_id\"):\n",
        "    # label\n",
        "    ohe_label = np.array([np.eye(24)[i] for i in df[\"species_id\"].unique()]).sum(0)\n",
        "    # position\n",
        "    pos = (df[[\"t_min\", \"t_max\"]].values/60*118).astype(int)\n",
        "    position_label = np.zeros((24, 118))\n",
        "    for i, (h, t) in enumerate(pos):\n",
        "        position_label[df[\"species_id\"].iloc[i], h:t] = 1\n",
        "    # make dict\n",
        "    label_dict[recording_id] = np.hstack([ohe_label.reshape(24, 1), position_label])\n",
        "\n",
        "for recording_id, df in train_fp.groupby(\"recording_id\"):\n",
        "    try:\n",
        "        _ = label_dict[recording_id]\n",
        "        continue\n",
        "    except KeyError:\n",
        "        label_dict[recording_id] = np.zeros((24, 119))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8uwGc9e_ynVQ"
      },
      "source": [
        "def set_seed(seed: int = 42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)  # type: ignore\n",
        "    torch.backends.cudnn.deterministic = True  # type: ignore\n",
        "    torch.backends.cudnn.benchmark = True  # type: ignore"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RmoJ3PU5iBmx"
      },
      "source": [
        "SIZE = 224\n",
        "\n",
        "class TimeMask:\n",
        "    def __init__(self, T=40, num_masks=1, replace_with_zero=True):\n",
        "        self.T = T\n",
        "        self.num_masks = num_masks\n",
        "        self.replace_with_zero = replace_with_zero\n",
        "\n",
        "    def __call__(self, spec):\n",
        "        cloned = spec.clone()\n",
        "        len_spectro = cloned.shape[2]\n",
        "    \n",
        "        for i in range(0, self.num_masks):\n",
        "            t = random.randrange(0, self.T)\n",
        "            t_zero = random.randrange(0, len_spectro - t)\n",
        "\n",
        "            # avoids randrange error if values are equal and range is empty\n",
        "            if (t_zero == t_zero + t): return cloned\n",
        "\n",
        "            mask_end = random.randrange(t_zero, t_zero + t)\n",
        "            if (self.replace_with_zero): cloned[:,:,t_zero:mask_end] = 0\n",
        "            else: cloned[:,:,t_zero:mask_end] = cloned.mean()\n",
        "        return cloned\n",
        "\n",
        "class FreqMask:\n",
        "    def __init__(self, F=30, num_masks=1, replace_with_zero=True):\n",
        "        self.F = F\n",
        "        self.num_masks = num_masks\n",
        "        self.replace_with_zero = replace_with_zero\n",
        "\n",
        "    def __call__(self, spec):\n",
        "        cloned = spec.clone()\n",
        "        num_mel_channels = cloned.shape[1]\n",
        "    \n",
        "        for i in range(0, self.num_masks):        \n",
        "            f = random.randrange(0, self.F)\n",
        "            f_zero = random.randrange(0, num_mel_channels - f)\n",
        "\n",
        "            # avoids randrange error if values are equal and range is empty\n",
        "            if (f_zero == f_zero + f): return cloned\n",
        "\n",
        "            mask_end = random.randrange(f_zero, f_zero + f) \n",
        "            if (self.replace_with_zero): cloned[:, f_zero:mask_end] = 0\n",
        "            else: cloned[:, f_zero:mask_end] = cloned.mean()\n",
        "    \n",
        "        return cloned\n",
        "\n",
        "def mono_to_color(\n",
        "    X: np.ndarray, mean=None, std=None,\n",
        "    norm_max=None, norm_min=None, eps=1e-6\n",
        "):\n",
        "    # Stack X as [X,X,X]\n",
        "    X = np.stack([X, X, X], axis=-1)\n",
        "\n",
        "    # Standardize\n",
        "    mean = mean or X.mean()\n",
        "    X = X - mean\n",
        "    std = std or X.std()\n",
        "    Xstd = X / (std + eps)\n",
        "    _min, _max = Xstd.min(), Xstd.max()\n",
        "    norm_max = norm_max or _max\n",
        "    norm_min = norm_min or _min\n",
        "    if (_max - _min) > eps:\n",
        "        # Normalize to [0, 255]\n",
        "        V = Xstd\n",
        "        V[V < norm_min] = norm_min\n",
        "        V[V > norm_max] = norm_max\n",
        "        V = 255 * (V - norm_min) / (norm_max - norm_min)\n",
        "        V = V.astype(np.uint8)\n",
        "    else:\n",
        "        # Just zero\n",
        "        V = np.zeros_like(Xstd, dtype=np.uint8)\n",
        "    return V\n",
        "\n",
        "class SpectrogramFromNpz(torch.utils.data.Dataset):\n",
        "    def __init__(self, X, y, mode):\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "        self.mode = mode\n",
        "        self.to_tensor = transforms.ToTensor()\n",
        "        #self.resize = transforms.Resize((SIZE, SIZE), interpolation=2)\n",
        "        self.norm = transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
        "        self.augument_funcs = transforms.RandomApply([\n",
        "            #transforms.Lambda(lambda img: transforms.functional.adjust_gamma(img, gamma=2, gain=1)),\n",
        "            #FreqMask(),\n",
        "            TimeMask(),\n",
        "        ], p=0.5),\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.y)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        fname = self.X[idx]\n",
        "        label = self.y[idx]\n",
        "\n",
        "        if self.mode in [\"train\", \"valid\"]:\n",
        "            path = f\"./train/{fname}.npy\"\n",
        "        elif self.mode == \"test\":\n",
        "            path = f\"./test/{fname}.npy\"\n",
        "        mel = np.load(path)\n",
        "\n",
        "        image = mono_to_color(mel)\n",
        "        image = self.to_tensor(image)\n",
        "        image = self.norm(image)\n",
        "        #image = self.resize(image)\n",
        "        if self.mode == \"train\":\n",
        "            for aug in self.augument_funcs:\n",
        "                image = aug(image)\n",
        "\n",
        "        return image, label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z6g9RffbpbuV"
      },
      "source": [
        "# https://www.kaggle.com/c/rfcx-species-audio-detection/discussion/198418\n",
        "\n",
        "# LRAP. Instance-level average\n",
        "# Assume float preds [BxC], labels [BxC] of 0 or 1\n",
        "def LRAP(preds, labels):\n",
        "    # Ranks of the predictions\n",
        "    ranked_classes = torch.argsort(preds, dim=-1, descending=True)\n",
        "    # i, j corresponds to rank of prediction in row i\n",
        "    class_ranks = torch.zeros_like(ranked_classes)\n",
        "    for i in range(ranked_classes.size(0)):\n",
        "        for j in range(ranked_classes.size(1)):\n",
        "            class_ranks[i, ranked_classes[i][j]] = j + 1\n",
        "    # Mask out to only use the ranks of relevant GT labels\n",
        "    ground_truth_ranks = class_ranks * labels + (1e6) * (1 - labels)\n",
        "    # All the GT ranks are in front now\n",
        "    sorted_ground_truth_ranks, _ = torch.sort(ground_truth_ranks, dim=-1, descending=False)\n",
        "    pos_matrix = torch.tensor(np.array([i+1 for i in range(labels.size(-1))])).unsqueeze(0)\n",
        "    score_matrix = pos_matrix / sorted_ground_truth_ranks\n",
        "    score_mask_matrix, _ = torch.sort(labels, dim=-1, descending=True)\n",
        "    scores = score_matrix * score_mask_matrix\n",
        "    score = (scores.sum(-1) / labels.sum(-1)).mean()\n",
        "    return score.item()\n",
        "\n",
        "# label-level average\n",
        "# Assume float preds [BxC], labels [BxC] of 0 or 1\n",
        "def LWLRAP(preds, labels):\n",
        "    # Ranks of the predictions\n",
        "    ranked_classes = torch.argsort(preds, dim=-1, descending=True)\n",
        "    # i, j corresponds to rank of prediction in row i\n",
        "    class_ranks = torch.zeros_like(ranked_classes)\n",
        "    for i in range(ranked_classes.size(0)):\n",
        "        for j in range(ranked_classes.size(1)):\n",
        "            class_ranks[i, ranked_classes[i][j]] = j + 1\n",
        "    # Mask out to only use the ranks of relevant GT labels\n",
        "    ground_truth_ranks = class_ranks * labels + (1e6) * (1 - labels)\n",
        "    # All the GT ranks are in front now\n",
        "    sorted_ground_truth_ranks, _ = torch.sort(ground_truth_ranks, dim=-1, descending=False)\n",
        "    # Number of GT labels per instance\n",
        "    num_labels = labels.sum(-1)\n",
        "    pos_matrix = torch.tensor(np.array([i+1 for i in range(labels.size(-1))])).unsqueeze(0)\n",
        "    score_matrix = pos_matrix / sorted_ground_truth_ranks\n",
        "    score_mask_matrix, _ = torch.sort(labels, dim=-1, descending=True)\n",
        "    scores = score_matrix * score_mask_matrix\n",
        "    score = scores.sum() / labels.sum()\n",
        "    return score.item()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9sIaNWd8nfq8"
      },
      "source": [
        "def train_loop(train_data_loader, model, optimizer, scheduler):\n",
        "    model.train()\n",
        "    losses, lrs = [], []\n",
        "    for X, y in tqdm.tqdm_notebook(train_data_loader):\n",
        "        pos_y = y[:,:,1:].to(device)\n",
        "        y = y[:,:,0]\n",
        "        X, y = X.to(device), y.to(device)\n",
        "\n",
        "        b = beta(config.alpha, config.alpha)\n",
        "        X, y = mixup(X, y, b)\n",
        "\n",
        "        pseudo_label, clipwise_preds, attention_preds = model(X)\n",
        "        loss1 = nn.BCEWithLogitsLoss()(clipwise_preds, y)\n",
        "        loss2 = nn.BCEWithLogitsLoss()(attention_preds, pseudo_label)\n",
        "        loss3 = nn.BCEWithLogitsLoss()(attention_preds, pos_y)\n",
        "        #loss = (loss1 + loss2 + loss3) / 3\n",
        "        loss = loss1 + loss2*0.5 + loss3*0.5\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if scheduler is not None:\n",
        "            scheduler.step()\n",
        "\n",
        "        losses.append(loss.item())\n",
        "        lrs.append(np.array([param_group[\"lr\"] for param_group in optimizer.param_groups]).mean())\n",
        "    t_loss = np.array(losses).mean()\n",
        "    lr =  np.array(lrs).mean()\n",
        "    return t_loss, lr\n",
        "\n",
        "def valid_loop(valid_data_loader, model):\n",
        "    model.eval()\n",
        "    v_scores, v_losses = [], []\n",
        "    for X, y in tqdm.tqdm_notebook(valid_data_loader):\n",
        "        X, y = X.to(device), y.to(device)\n",
        "        y = y[:,:,0]\n",
        "\n",
        "        with torch.no_grad():\n",
        "            # pred = model(X)\n",
        "            _, pred, _ = model(X)\n",
        "        pred = pred.sigmoid()\n",
        "\n",
        "        score = LRAP(pred.cpu().sigmoid(), y.cpu())\n",
        "        v_scores.append(score)\n",
        "\n",
        "        loss = nn.BCEWithLogitsLoss()(pred, y)\n",
        "        loss = loss.item()\n",
        "        v_losses.append(loss)\n",
        "    valid_score, valid_loss = np.array(v_scores).mean(), np.array(v_losses).mean()\n",
        "    return valid_score, valid_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9pUAs2fvgefc"
      },
      "source": [
        "N_FOLD = 5\n",
        "WORKS = 4\n",
        "\n",
        "def parse_labels(recording_id):\n",
        "    try:\n",
        "        label = label_dict[recording_id]\n",
        "    except KeyError:\n",
        "        label = np.zeros(24)\n",
        "    return label\n",
        "\n",
        "def get_data_loader():\n",
        "    labels = np.array(list(label_dict.values()))\n",
        "    fnames = np.array(list(label_dict.keys()))\n",
        "\n",
        "    mskf = MultilabelStratifiedKFold(n_splits=N_FOLD, shuffle=True, random_state=config.seed)\n",
        "    for fold, (train_index, valid_index) in enumerate(mskf.split(fnames, labels[:, :, 0])):\n",
        "        if config.fold != fold:\n",
        "            continue\n",
        "        train_X, train_y = fnames[train_index], labels[train_index]\n",
        "        valid_X, valid_y = fnames[valid_index], labels[valid_index]\n",
        "\n",
        "        train_datasets = SpectrogramFromNpz(train_X, train_y, \"train\")\n",
        "        valid_datasets = SpectrogramFromNpz(valid_X, valid_y, \"valid\")  # ←修正\n",
        "\n",
        "        train_data_loader = torch.utils.data.DataLoader(train_datasets, batch_size=config.batch_size, shuffle=True, num_workers=WORKS)\n",
        "        valid_data_loader = torch.utils.data.DataLoader(valid_datasets, batch_size=config.batch_size, shuffle=False, num_workers=WORKS)\n",
        "\n",
        "    return train_data_loader, valid_data_loader"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y89T06MyQIN3"
      },
      "source": [
        "def mixup(input, target, gamma):\n",
        "    # target is onehot format!\n",
        "    perm = torch.randperm(input.size(0))\n",
        "    perm_input = input[perm]\n",
        "    perm_target = target[perm]\n",
        "    return input.mul_(gamma).add_(1 - gamma, perm_input), target.mul_(gamma).add_(1 - gamma, perm_target)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tNNlajbwlgzS"
      },
      "source": [
        "### モデル"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YaVbmehScyn4"
      },
      "source": [
        "class BirdcallNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(BirdcallNet, self).__init__()\n",
        "        self.n_label = 24\n",
        "        resnet = resnet18(pretrained=True)\n",
        "        self.resnet_head = nn.Sequential(*list(resnet.children())[:-2])\n",
        "        self.l8_a = nn.Conv1d(512, self.n_label, 1, bias=False)\n",
        "        self.l8_b = nn.Conv1d(512, self.n_label, 1, bias=False)\n",
        "\n",
        "    def forward(self, x):  # input x: (batch, channel, Hz, time)\n",
        "        frames_num = x.shape[3]\n",
        "        x = x.transpose(3, 2)  # (batch, channel, time, Hz)\n",
        "\n",
        "        h = self.resnet_head(x)  # (batch, unit, time, Hz)\n",
        "        \n",
        "        h = F.relu(h)\n",
        "        h  = torch.mean(h, dim=3)  # (batch, unit, time)\n",
        "        \n",
        "        xa = self.l8_a(h)  # (batch, n_class, time)\n",
        "        xb = self.l8_b(h)  # (batch, n_class, time)\n",
        "        xb = torch.softmax(xb, dim=2)\n",
        "\n",
        "        pseudo_label = (xa.sigmoid() >= 0.5).float()\n",
        "        clipwise_preds = torch.sum(xa * xb, dim=2)\n",
        "        attention_preds = xb\n",
        "        \n",
        "        return pseudo_label, clipwise_preds, attention_preds"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VSMmN2u-lar0"
      },
      "source": [
        "### 実行パラメーター"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7wy4JmnKn0oh"
      },
      "source": [
        "EXP_NAME = \"exp0001_first_sample\"\n",
        "OUTPUT = f\"./drive/MyDrive/Study/RFCX/output/{EXP_NAME}\"\n",
        "!mkdir -p {config.OUTPUT}\n",
        "\n",
        "config = wandb.config\n",
        "\n",
        "config.seed = 416\n",
        "config.learning_rate = 1e-3\n",
        "config.batch_size = 64\n",
        "config.num_epochs = 50\n",
        "#config.t_max = 10\n",
        "config.fold = 0\n",
        "config.alpha = 0.1\n",
        "\n",
        "wandb.init(project=\"rfcx\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S1AiWIZ3yUd3"
      },
      "source": [
        "### 実行"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6cOLDgRqetqw"
      },
      "source": [
        "set_seed(config.seed)\n",
        "\n",
        "train_data_loader, valid_data_loader = get_data_loader()\n",
        "\n",
        "model = BirdcallNet()\n",
        "model.to(device)\n",
        "optimizer = Adam(model.parameters(), lr=config.learning_rate)\n",
        "#scheduler = CosineAnnealingLR(optimizer, T_max=len(train_data_loader)*config.t_max, eta_min=0.0)\n",
        "scheduler = None\n",
        "\n",
        "wandb.watch(model)\n",
        "\n",
        "best_score = 0\n",
        "for epoch in range(config.num_epochs):\n",
        "    print(f\"### epoch {epoch} ###\")\n",
        "    t_loss, lr = train_loop(train_data_loader, model, optimizer, scheduler)\n",
        "    v_score, v_loss = valid_loop(valid_data_loader, model)\n",
        "\n",
        "    if best_score < v_score:\n",
        "        print(\"best model update !!!\")\n",
        "        torch.save(model.state_dict(), f\"{OUTPUT}/birdcallnet_f{config.fold}_latest_model.bin\")\n",
        "        best_score = v_score\n",
        "    \n",
        "    wandb.log({\"train loss\": t_loss, \"lr\": lr, \"valid loss\": v_loss, \"valid score\": v_score, \"best score\": best_score})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SmBn1myC9Ymv"
      },
      "source": [
        "画像確認"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hco6fDOaVggg"
      },
      "source": [
        "# 0.7393\n",
        "path = f\"./train/64e252faf.npy\"\n",
        "mel = np.load(path)\n",
        "\n",
        "image = mono_to_color(mel)\n",
        "image = image[:,:200,:]\n",
        "print(image.shape)\n",
        "plt.imshow(image)\n",
        "\n",
        "image = transforms.ToTensor()(image)\n",
        "plt.imshow(np.moveaxis((image).numpy(), 0, 2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bbp8c70ajJEF"
      },
      "source": [
        "モデルの挙動確認"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1XEVNJ-Jr1HH"
      },
      "source": [
        "train_data_loader, valid_data_loader = get_data_loader()\n",
        "for X, y in tqdm.tqdm_notebook(train_data_loader):\n",
        "    break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RNlvLFw7Ru8h"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aBrbtgDKWrjW"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I8XPRdROskQ8"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}