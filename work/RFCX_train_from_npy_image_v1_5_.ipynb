{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RFCX_train_from_npy_image_v1_5_.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "t3l_5_WXkHrd"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ITzFStSplR82"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MMoGy2fAk8Sa"
      },
      "source": [
        "%%time\n",
        "# 大体10分くらい\n",
        "\n",
        "!pip install -q kaggle\n",
        "!mkdir -p .kaggle\n",
        "!cp \"./drive/My Drive/Study/config/kaggle.json\" .kaggle/\n",
        "!chmod 600 .kaggle/kaggle.json\n",
        "!mv .kaggle /root\n",
        "\n",
        "!kaggle datasets download \"theoviel/rcfx-spectrograms-32-khz\"\n",
        "!unzip rcfx-spectrograms-32-khz.zip > /dev/null\n",
        "!rm -rf rcfx-spectrograms-32-khz.zip \n",
        "\n",
        "!pip install -U iterative-stratification albumentations wandb  > /dev/null\n",
        "!wandb login e0792bb688a0d18e359df7438c45da90f8794091"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3zAeTPFiliqi"
      },
      "source": [
        "import os\n",
        "import tqdm\n",
        "import random\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n",
        "from datetime import datetime\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from numpy.random import beta\n",
        "\n",
        "import torch\n",
        "from torchvision.models import resnet18\n",
        "import torch.nn as nn\n",
        "from torch.optim import Adam, AdamW\n",
        "from torch.optim.lr_scheduler import CosineAnnealingLR, ReduceLROnPlateau\n",
        "from torchvision import transforms\n",
        "from torch.nn import functional as F\n",
        "\n",
        "import albumentations as A\n",
        "\n",
        "import wandb\n",
        "\n",
        "device = torch.device(\"cuda\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HCDqE-MXlkkz"
      },
      "source": [
        "DATA_ROOT = \"./drive/MyDrive/Study/RFCX/input\"\n",
        "\n",
        "sample_submission = pd.read_csv(f\"{DATA_ROOT}/sample_submission.csv\")\n",
        "train_fp = pd.read_csv(f\"{DATA_ROOT}/train_fp.csv\")\n",
        "train_tp = pd.read_csv(f\"{DATA_ROOT}/train_tp.csv\")\n",
        "\n",
        "(train_tp[\"f_max\"].max()/16000)*128, (train_tp[\"f_min\"].min()/16000)*128"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xpj4TOhgtZXd"
      },
      "source": [
        "label_dict = {}\n",
        "pos_dict = {}\n",
        "for recording_id, df in train_tp.groupby(\"recording_id\"):\n",
        "    position_label = np.zeros((24, 3751))\n",
        "    middle = []\n",
        "    for species_id, t_min, t_max in df.values[:, [1, 3, 5]]:\n",
        "        h, t = int(3751*(t_min/60)), int(3751*(t_max/60))\n",
        "        position_label[species_id, h:t] = 1\n",
        "        m = (t + h)//2\n",
        "        middle.append(m)\n",
        "    label_dict[recording_id] = position_label\n",
        "    pos_dict[recording_id] = middle\n",
        "\n",
        "counts_df = train_tp[\"species_id\"].value_counts()\n",
        "max_counts = counts_df.max()\n",
        "label_weight = max_counts / counts_df\n",
        "pos_weights = torch.Tensor(label_weight.sort_index().values).to(device)\n",
        "\n",
        "fnames = np.array(list(label_dict.keys()))\n",
        "labels = np.array(list(label_dict.values())).sum(2)\n",
        "\n",
        "test_fnames = sample_submission[\"recording_id\"].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QJDefaQjV1vt"
      },
      "source": [
        "#train_tp[\"species_id\"].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3TsIfySgVUq0"
      },
      "source": [
        "fp_label_dict = {}\n",
        "fp_pos_dict = {}\n",
        "for recording_id, df in train_fp.groupby(\"recording_id\"):\n",
        "    position_label = np.zeros((24, 3751))\n",
        "    middle = []\n",
        "    for species_id, t_min, t_max in df.values[:, [1, 3, 5]]:\n",
        "        h, t = int(3751*(t_min/60)), int(3751*(t_max/60))\n",
        "        m = (t + h)//2\n",
        "        middle.append(m)\n",
        "    fp_label_dict[recording_id] = position_label\n",
        "    fp_pos_dict[recording_id] = middle"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kv4tt5lLl03a"
      },
      "source": [
        "# https://www.kaggle.com/c/rfcx-species-audio-detection/discussion/198418\n",
        "\n",
        "# LRAP. Instance-level average\n",
        "# Assume float preds [BxC], labels [BxC] of 0 or 1\n",
        "def LRAP(preds, labels):\n",
        "    # Ranks of the predictions\n",
        "    ranked_classes = torch.argsort(preds, dim=-1, descending=True)\n",
        "    # i, j corresponds to rank of prediction in row i\n",
        "    class_ranks = torch.zeros_like(ranked_classes)\n",
        "    for i in range(ranked_classes.size(0)):\n",
        "        for j in range(ranked_classes.size(1)):\n",
        "            class_ranks[i, ranked_classes[i][j]] = j + 1\n",
        "    # Mask out to only use the ranks of relevant GT labels\n",
        "    ground_truth_ranks = class_ranks * labels + (1e6) * (1 - labels)\n",
        "    # All the GT ranks are in front now\n",
        "    sorted_ground_truth_ranks, _ = torch.sort(ground_truth_ranks, dim=-1, descending=False)\n",
        "    pos_matrix = torch.tensor(np.array([i+1 for i in range(labels.size(-1))])).unsqueeze(0)\n",
        "    score_matrix = pos_matrix / sorted_ground_truth_ranks\n",
        "    score_mask_matrix, _ = torch.sort(labels, dim=-1, descending=True)\n",
        "    scores = score_matrix * score_mask_matrix\n",
        "    score = (scores.sum(-1) / labels.sum(-1)).mean()\n",
        "    return score.item()\n",
        "\n",
        "# label-level average\n",
        "# Assume float preds [BxC], labels [BxC] of 0 or 1\n",
        "def LWLRAP(preds, labels):\n",
        "    # Ranks of the predictions\n",
        "    ranked_classes = torch.argsort(preds, dim=-1, descending=True)\n",
        "    # i, j corresponds to rank of prediction in row i\n",
        "    class_ranks = torch.zeros_like(ranked_classes)\n",
        "    for i in range(ranked_classes.size(0)):\n",
        "        for j in range(ranked_classes.size(1)):\n",
        "            class_ranks[i, ranked_classes[i][j]] = j + 1\n",
        "    # Mask out to only use the ranks of relevant GT labels\n",
        "    ground_truth_ranks = class_ranks * labels + (1e6) * (1 - labels)\n",
        "    # All the GT ranks are in front now\n",
        "    sorted_ground_truth_ranks, _ = torch.sort(ground_truth_ranks, dim=-1, descending=False)\n",
        "    # Number of GT labels per instance\n",
        "    num_labels = labels.sum(-1)\n",
        "    pos_matrix = torch.tensor(np.array([i+1 for i in range(labels.size(-1))])).unsqueeze(0)\n",
        "    score_matrix = pos_matrix / sorted_ground_truth_ranks\n",
        "    score_mask_matrix, _ = torch.sort(labels, dim=-1, descending=True)\n",
        "    scores = score_matrix * score_mask_matrix\n",
        "    score = scores.sum() / labels.sum()\n",
        "    return score.item()\n",
        "\n",
        "def set_seed(seed: int = 42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)  # type: ignore\n",
        "    torch.backends.cudnn.deterministic = True  # type: ignore\n",
        "    torch.backends.cudnn.benchmark = True  # type: ignore\n",
        "\n",
        "def parse_labels(recording_id):\n",
        "    try:\n",
        "        label = label_dict[recording_id]\n",
        "    except KeyError:\n",
        "        label = np.zeros(24)\n",
        "    return label\n",
        "\n",
        "def mixup(input, target, gamma):\n",
        "    # target is onehot format!\n",
        "    perm = torch.randperm(input.size(0))\n",
        "    perm_input = input[perm]\n",
        "    perm_target = target[perm]\n",
        "    return input.mul_(gamma).add_(1 - gamma, perm_input), target.mul_(gamma).add_(1 - gamma, perm_target)\n",
        "\n",
        "def last_layer_mixup(target, gamma):\n",
        "    perm = torch.randperm(target.size(0))\n",
        "    perm_target = target[perm]\n",
        "    return perm, target.mul_(gamma).add_(1 - gamma, perm_target)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZzKRUeO9lqA4"
      },
      "source": [
        "class TimeMask:\n",
        "    def __init__(self, T=40, num_masks=1, replace_with_zero=True):\n",
        "        self.T = T\n",
        "        self.num_masks = num_masks\n",
        "        self.replace_with_zero = replace_with_zero\n",
        "\n",
        "    def __call__(self, spec):\n",
        "        cloned = spec.clone()\n",
        "        len_spectro = cloned.shape[2]\n",
        "    \n",
        "        for i in range(0, self.num_masks):\n",
        "            t = random.randrange(0, self.T)\n",
        "            t_zero = random.randrange(0, len_spectro - t)\n",
        "\n",
        "            # avoids randrange error if values are equal and range is empty\n",
        "            if (t_zero == t_zero + t): return cloned\n",
        "\n",
        "            mask_end = random.randrange(t_zero, t_zero + t)\n",
        "            if (self.replace_with_zero): cloned[:,:,t_zero:mask_end] = 0\n",
        "            else: cloned[:,:,t_zero:mask_end] = cloned.mean()\n",
        "        return cloned\n",
        "\n",
        "class FreqMask:\n",
        "    def __init__(self, F=30, num_masks=1, replace_with_zero=True):\n",
        "        self.F = F\n",
        "        self.num_masks = num_masks\n",
        "        self.replace_with_zero = replace_with_zero\n",
        "\n",
        "    def __call__(self, spec):\n",
        "        cloned = spec.clone()\n",
        "        num_mel_channels = cloned.shape[1]\n",
        "    \n",
        "        for i in range(0, self.num_masks):        \n",
        "            f = random.randrange(0, self.F)\n",
        "            f_zero = random.randrange(0, num_mel_channels - f)\n",
        "\n",
        "            # avoids randrange error if values are equal and range is empty\n",
        "            if (f_zero == f_zero + f): return cloned\n",
        "\n",
        "            mask_end = random.randrange(f_zero, f_zero + f) \n",
        "            if (self.replace_with_zero): cloned[:, f_zero:mask_end] = 0\n",
        "            else: cloned[:, f_zero:mask_end] = cloned.mean()\n",
        "    \n",
        "        return cloned\n",
        "\n",
        "def mono_to_color(\n",
        "    X: np.ndarray, mean=None, std=None,\n",
        "    norm_max=None, norm_min=None, eps=1e-6\n",
        "):\n",
        "    # Stack X as [X,X,X]\n",
        "    X = np.stack([X, X, X], axis=-1)\n",
        "\n",
        "    # Standardize\n",
        "    mean = mean or X.mean()\n",
        "    X = X - mean\n",
        "    std = std or X.std()\n",
        "    Xstd = X / (std + eps)\n",
        "    _min, _max = Xstd.min(), Xstd.max()\n",
        "    norm_max = norm_max or _max\n",
        "    norm_min = norm_min or _min\n",
        "    if (_max - _min) > eps:\n",
        "        # Normalize to [0, 255]\n",
        "        V = Xstd\n",
        "        V[V < norm_min] = norm_min\n",
        "        V[V > norm_max] = norm_max\n",
        "        V = 255 * (V - norm_min) / (norm_max - norm_min)\n",
        "        V = V.astype(np.uint8)\n",
        "    else:\n",
        "        # Just zero\n",
        "        V = np.zeros_like(Xstd, dtype=np.uint8)\n",
        "    return V\n",
        "\n",
        "H_POS = [32, 64, 128, 256]\n",
        "WINDOW = 512\n",
        "#H_POS = [32, 64, 128]\n",
        "#WINDOW = 256\n",
        "MAX_SEQ = 3751 - 1\n",
        "def extract_ht_pos(pos):\n",
        "    h_pos = [p for p in H_POS if (pos - p) > 0]\n",
        "    if len(h_pos) > 0:\n",
        "        h_pos = random.choice(h_pos)\n",
        "    else:\n",
        "        h_pos = pos\n",
        "    t_pos = WINDOW - h_pos\n",
        "    h, t = pos-h_pos, pos+t_pos\n",
        "    if t > MAX_SEQ:\n",
        "        h, t = MAX_SEQ-WINDOW, MAX_SEQ\n",
        "    return h, t\n",
        "\n",
        "class SpectrogramFromNpz(torch.utils.data.Dataset):\n",
        "    def __init__(self, fname, mode):\n",
        "        self.fname = fname\n",
        "        self.mode = mode\n",
        "        self.to_tensor = transforms.ToTensor()\n",
        "        self.norm = transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
        "        self.augument_funcs_a = A.Compose([\n",
        "            A.RandomBrightnessContrast(p=0.5),\n",
        "            #A.RandomCrop(height=100, width=3751, p=0.5),\n",
        "        ])\n",
        "        self.augument_funcs_b = transforms.RandomApply([\n",
        "            transforms.Lambda(lambda img: transforms.functional.adjust_gamma(img, gamma=2, gain=1)),\n",
        "            TimeMask(),\n",
        "            FreqMask(),\n",
        "        ], p=0.5)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.fname)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        fname = self.fname[idx]\n",
        "\n",
        "        # position\n",
        "        try:\n",
        "            pos = pos_dict[fname]\n",
        "            pos = random.choice(pos)\n",
        "            h, t = extract_ht_pos(pos)\n",
        "        except KeyError:\n",
        "            try:\n",
        "                pos = fp_pos_dict[fname]\n",
        "                pos = random.choice(pos)\n",
        "                h, t = extract_ht_pos(pos)\n",
        "            except KeyError:\n",
        "                h, t = None, None\n",
        "\n",
        "        # load images\n",
        "        if self.mode in [\"train\", \"valid\"]:\n",
        "            path = f\"./train/{fname}.npy\"\n",
        "        elif self.mode == \"test\":\n",
        "            path = f\"./test/{fname}.npy\"\n",
        "        mel = np.load(path)\n",
        "        image = mono_to_color(mel)\n",
        "        #image = image[-110:, :, :]  # low pass filter\n",
        "\n",
        "        # augument\n",
        "        if self.mode == \"train\":\n",
        "            image = self.augument_funcs_a(image=image)[\"image\"]\n",
        "            image = self.to_tensor(image)\n",
        "            image = self.augument_funcs_b(image)\n",
        "            image = image[:, :, h:t]\n",
        "        else:\n",
        "            image = self.to_tensor(image)\n",
        "        image = self.norm(image)\n",
        "\n",
        "        # label\n",
        "        try:\n",
        "            label = label_dict[fname]\n",
        "        except KeyError:\n",
        "            try:\n",
        "                label = fp_label_dict[fname]\n",
        "            except KeyError:\n",
        "                label = None\n",
        "        if self.mode == \"train\":\n",
        "            label = label[:, h:t]\n",
        "\n",
        "        return image, label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nDWcvxkKl70K"
      },
      "source": [
        "EPS = 1e-7\n",
        "def train_loop(train_data_loader, model, optimizer, scheduler):\n",
        "    model.train()\n",
        "    losses, lrs = [], []\n",
        "    for X, y in train_data_loader:\n",
        "        X = X.to(device)\n",
        "        y = (y.sum(2) > 0).int().float().to(device)\n",
        "\n",
        "        #LABEL_SMOOTHING = 0.2\n",
        "        #y = y * (1 - LABEL_SMOOTHING) + (LABEL_SMOOTHING/24)  # label smoothing\n",
        "\n",
        "        b = beta(config.alpha, config.alpha)\n",
        "\n",
        "        perm, _y = last_layer_mixup(y, b)\n",
        "        pseudo_label, clipwise_preds, attention_preds, clipwise_preds_max = model(X, perm, b)\n",
        "\n",
        "        loss1 = nn.BCEWithLogitsLoss(pos_weight=pos_weights)(clipwise_preds, _y)\n",
        "        loss_none = nn.BCEWithLogitsLoss(reduction=\"none\")(attention_preds, pseudo_label)\n",
        "        loss2 = (loss_none.mean(2) * pos_weights).mean()\n",
        "        loss3 = nn.BCEWithLogitsLoss(pos_weight=pos_weights)(clipwise_preds_max, _y)\n",
        "        loss_a = loss1 + loss2 + loss3*0.5\n",
        "\n",
        "\n",
        "        \"\"\"\n",
        "        _X, y = mixup(X, y, b)\n",
        "        _pseudo_label, _clipwise_preds, _attention_preds, _clipwise_preds_max = model(_X)\n",
        "\n",
        "        _loss1 = nn.BCEWithLogitsLoss(pos_weight=pos_weights)(_clipwise_preds, y)\n",
        "        _loss_none = nn.BCEWithLogitsLoss(reduction=\"none\")(_attention_preds, _pseudo_label)\n",
        "        _loss2 = (_loss_none.mean(2) * pos_weights).mean()\n",
        "        _loss3 = nn.BCEWithLogitsLoss(pos_weight=pos_weights)(_clipwise_preds_max, y)\n",
        "        loss_b = _loss1 + _loss2 + _loss3*0.5\n",
        "\n",
        "\n",
        "        loss = (loss_a + loss_b)/2\n",
        "        \"\"\"\n",
        "        loss = loss_a\n",
        "\n",
        "        #_loss1 = nn.BCEWithLogitsLoss(reduction=\"none\")(clipwise_preds, y)\n",
        "        #_loss1 = (_loss1 * (y != 1).int()).mean()\n",
        "        #loss1 += _loss1\n",
        "\n",
        "        #loss2 = nn.BCEWithLogitsLoss()(attention_preds, pseudo_label)\n",
        "        \n",
        "        #_loss3 = nn.BCEWithLogitsLoss(reduction=\"none\")(clipwise_preds_max, y)\n",
        "        #_loss3 = (_loss3 * (y != 1).int()).mean()\n",
        "        #loss3 += _loss3\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if scheduler is not None:\n",
        "            scheduler.step()\n",
        "\n",
        "        losses.append(loss.item())\n",
        "        lrs.append(np.array([param_group[\"lr\"] for param_group in optimizer.param_groups]).mean())\n",
        "    t_loss = np.array(losses).mean()\n",
        "    lr =  np.array(lrs).mean()\n",
        "    return t_loss, lr\n",
        "\n",
        "eval_img_pos = [[0, WINDOW]]\n",
        "for idx in range(1, 8):\n",
        "#for idx in range(1, 18):\n",
        "    h, t = eval_img_pos[idx-1][0], eval_img_pos[idx-1][1]\n",
        "    h = t - 51\n",
        "    #h = t - 50\n",
        "    t = h + WINDOW\n",
        "    eval_img_pos.append([h, t])\n",
        "    \n",
        "def valid_loop(valid_data_loader, model):\n",
        "    model.eval()\n",
        "    v_scores, v_losses = [], []\n",
        "    for X, y in valid_data_loader:\n",
        "        \n",
        "        preds = []\n",
        "        for h, t in eval_img_pos:\n",
        "            with torch.no_grad():\n",
        "                #_, pred, _ = model(X[:,:,:,h:t].to(device))\n",
        "                _, pred, _, pred_max = model(X[:,:,:,h:t].to(device))\n",
        "            pred = pred.sigmoid()\n",
        "            pred_max = pred_max.sigmoid()\n",
        "            pred = (pred + pred_max)/2\n",
        "            preds.append(pred)\n",
        "        max_pred, _  = torch.max(torch.stack(preds), dim=0)\n",
        "\n",
        "        score = LRAP(max_pred.cpu(), (y.sum(2) > 0).int())\n",
        "        loss = nn.BCEWithLogitsLoss()(max_pred.cpu(), (y.sum(2) > 0).float())\n",
        "        v_scores.append(score)\n",
        "        v_losses.append(loss.item())\n",
        "\n",
        "    valid_score, valid_loss = np.array(v_scores).mean(), np.array(v_losses).mean()\n",
        "    return valid_score, valid_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p3Ka8mxKmCka"
      },
      "source": [
        "class RFCXNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(RFCXNet, self).__init__()\n",
        "        self.n_label = 24\n",
        "        resnet = resnet18(pretrained=True)\n",
        "        self.resnet_head = nn.Sequential(*list(resnet.children())[:-2])\n",
        "        self.l8_a = nn.Conv1d(512, self.n_label, 1, bias=False)\n",
        "        self.l8_b = nn.Conv1d(512, self.n_label, 1, bias=False)\n",
        "\n",
        "    def forward(self, x, perm=None, gamma=None):  # input x: (batch, channel, Hz, time)\n",
        "        frames_num = x.shape[3]\n",
        "        x = x.transpose(3, 2)  # (batch, channel, time, Hz)\n",
        "\n",
        "        h = self.resnet_head(x)  # (batch, unit, time, Hz)\n",
        "        if perm is not None:\n",
        "            h = gamma * h + (1 - gamma) * h[perm]\n",
        "        \n",
        "        h = F.relu(h)\n",
        "        h  = torch.mean(h, dim=3)  # (batch, unit, time)\n",
        "        \n",
        "        xa = self.l8_a(h)  # (batch, n_class, time)\n",
        "        xb = self.l8_b(h)  # (batch, n_class, time)\n",
        "        xb = torch.softmax(xb, dim=2)\n",
        "\n",
        "        pseudo_label = (xa.sigmoid() >= 0.7).float()\n",
        "        clipwise_preds = torch.sum(xa * xb, dim=2)\n",
        "        clipwise_preds_max, _ = torch.max(xa, dim=2)\n",
        "        attention_preds = xb\n",
        "        \n",
        "        return pseudo_label, clipwise_preds, attention_preds, clipwise_preds_max"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c8xtDWjwPpLN"
      },
      "source": [
        "SEED = 416\n",
        "N_FOLD = 5\n",
        "WORKS = 0\n",
        "EXP_NAME = \"exp0040_with_last_mixup\"\n",
        "OUTPUT = f\"./drive/MyDrive/Study/RFCX/output/{EXP_NAME}\"\n",
        "\n",
        "!mkdir -p {OUTPUT}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7bBbq5JIx6E2"
      },
      "source": [
        "mskf = MultilabelStratifiedKFold(n_splits=5, shuffle=True, random_state=0)\n",
        "for fold, (train_index, valid_index) in enumerate(mskf.split(fnames, labels)):\n",
        "    #if fold in [0, 1, 2]:\n",
        "    #    continue\n",
        "    print(datetime.now(), f\"\\t: ### FOLD-{fold} ###\")\n",
        "    set_seed(SEED)\n",
        "    wandb.init(project=\"rfcx\", name=f\"{EXP_NAME}_f{fold}\")\n",
        "\n",
        "    # hyper parameter\n",
        "    config = wandb.config\n",
        "    config.seed = 416\n",
        "    config.learning_rate = 1e-3\n",
        "    config.batch_size = 64\n",
        "    config.num_epochs = 50\n",
        "    config.alpha = 0.1\n",
        "    config.t_max = 10\n",
        "    config.factor = 0.5\n",
        "\n",
        "    config.exp_name = EXP_NAME\n",
        "    config.fold = fold\n",
        "\n",
        "    train_fname = fnames[train_index]\n",
        "    valid_fname = fnames[valid_index]\n",
        "\n",
        "    #train_datasets = SpectrogramFromNpz(train_fname, \"train\")\n",
        "    fp_fnames = random.sample(list(fp_label_dict.keys()), 50)\n",
        "    train_datasets = SpectrogramFromNpz(train_fname.tolist()+fp_fnames, \"train\")\n",
        "    train_data_loader = torch.utils.data.DataLoader(train_datasets, batch_size=config.batch_size, shuffle=True, num_workers=WORKS)\n",
        "    valid_datasets = SpectrogramFromNpz(valid_fname, \"valid\")\n",
        "    valid_data_loader = torch.utils.data.DataLoader(valid_datasets, batch_size=config.batch_size, shuffle=False, num_workers=WORKS)\n",
        "\n",
        "    model = RFCXNet()\n",
        "    model.to(device)\n",
        "    optimizer = Adam(model.parameters(), lr=config.learning_rate)\n",
        "    \n",
        "    scheduler = CosineAnnealingLR(optimizer, T_max=len(train_data_loader)*config.t_max, eta_min=0.0)\n",
        "    del train_datasets, train_data_loader\n",
        "\n",
        "    wandb.watch(model)\n",
        "\n",
        "    print(datetime.now(), \"\\t: start train\")\n",
        "    best_score, best_loss = 0, 9999\n",
        "    for epoch in range(config.num_epochs):\n",
        "        fp_fnames = random.sample(list(fp_label_dict.keys()), 50)\n",
        "        train_datasets = SpectrogramFromNpz(train_fname.tolist()+fp_fnames, \"train\")\n",
        "        train_data_loader = torch.utils.data.DataLoader(train_datasets, batch_size=config.batch_size, shuffle=True, num_workers=WORKS)\n",
        "\n",
        "        t_loss, lr = train_loop(train_data_loader, model, optimizer, scheduler)\n",
        "        v_score, v_loss = valid_loop(valid_data_loader, model)\n",
        "    \n",
        "        if best_score < v_score:\n",
        "            print(f\"epoch {epoch}: best score update !!!\")\n",
        "            torch.save(model.state_dict(), f\"{OUTPUT}/rfcxnet_f{config.fold}_best_score_model.bin\")\n",
        "            best_score = v_score\n",
        "        if best_loss > v_loss:\n",
        "            print(f\"epoch {epoch}: best loss update !!!\")\n",
        "            torch.save(model.state_dict(), f\"{OUTPUT}/rfcxnet_f{config.fold}_best_loss_model.bin\")\n",
        "            best_loss = v_loss\n",
        "    \n",
        "        wandb.log({\"train loss\": t_loss, \"lr\": lr, \"valid loss\": v_loss, \"valid score\": v_score, \"best score\": best_score, \"best loss\": best_loss})\n",
        "    print(datetime.now(), \"\\t: finish train\")\n",
        "\n",
        "    # predict test data\n",
        "    model.load_state_dict(torch.load(f\"{OUTPUT}/rfcxnet_f{config.fold}_best_score_model.bin\"))\n",
        "\n",
        "    test_datasets = SpectrogramFromNpz(test_fnames, \"test\")\n",
        "\n",
        "    lst = []\n",
        "    for idx, (X, _) in tqdm.tqdm_notebook(enumerate(test_datasets), total=1992):\n",
        "        preds = []\n",
        "        for h, t in eval_img_pos:\n",
        "            with torch.no_grad():\n",
        "                #_, pred, _,  = model(X[:,:,h:t].unsqueeze(0).to(device))\n",
        "                _, pred, _, pred_max = model(X[:,:,h:t].unsqueeze(0).to(device))\n",
        "            pred = pred.sigmoid()\n",
        "            pred_max = pred_max.sigmoid()\n",
        "            pred = (pred + pred_max)/2\n",
        "            preds.append(pred)\n",
        "        max_pred, _  = torch.max(torch.stack(preds), dim=0)\n",
        "        pred = max_pred.cpu().numpy()[0].tolist()\n",
        "\n",
        "        row = [test_fnames[idx]] + pred\n",
        "        lst.append(row)\n",
        "\n",
        "    fold_sub = pd.DataFrame(lst, columns=[\"recording_id\"]+[f\"s{i}\" for i in range(24)])\n",
        "    fold_sub.to_csv(f\"{OUTPUT}/rfcxnet_f{config.fold}_predict.csv\", index=None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HVIWrH5kEN7i"
      },
      "source": [
        "#import pandas as pd\n",
        "#import torch\n",
        "#!ls ./drive/MyDrive/Study/RFCX/output/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2B8DthnrYnYC"
      },
      "source": [
        "#EXP_NAME = \"exp0036_add_fp_data_max_posw_frame0.3\"\n",
        "#OUTPUT = f\"./drive/MyDrive/Study/RFCX/output/{EXP_NAME}\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bOR0_hcSoVC_"
      },
      "source": [
        "all_v_lst = []\n",
        "for fold in range(5):\n",
        "    df = pd.read_csv(f\"{OUTPUT}/rfcxnet_f{fold}_predict.csv\")\n",
        "    ids, v_lst = [], []\n",
        "    for row in df.values:\n",
        "        recording_id = row[0]\n",
        "        ids.append(recording_id)\n",
        "        v = torch.Tensor(row[1:].astype(float))\n",
        "        v_lst.append(v)\n",
        "    all_v_lst.append(torch.stack(v_lst, axis=0))\n",
        "\n",
        "all_preds = torch.stack(all_v_lst, axis=2).mean(2)\n",
        "#all_preds, _ = torch.stack(all_v_lst, axis=2).max(2)\n",
        "sub = pd.DataFrame(all_preds.tolist(), columns=df.columns[1:])\n",
        "sub = pd.concat([df[[\"recording_id\"]], sub], axis=1)\n",
        "sub.to_csv(f\"./submission_{EXP_NAME}.csv\", index=None)\n",
        "#sub.to_csv(f\"./submission_{EXP_NAME}_max.csv\", index=None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DR_fS5DXc_9-"
      },
      "source": [
        "#exp0021 = pd.read_csv(\"submission_exp0021_cut_and_sum.csv\")\n",
        "#exp0025 = pd.read_csv(\"submission_exp0025_window256.csv\")\n",
        "#df = pd.DataFrame((exp0021.values[:, 1:] + exp0025.values[:, 1:])/2, columns=exp0025.columns[1:])\n",
        "#pd.concat([exp0021[[\"recording_id\"]], df], axis=1).to_csv(\"exp0025_mix256_512.csv\", index=None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_zNaifz5dIHG"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dzOKCLj2dYGv"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wgKGfA29dKDz"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}