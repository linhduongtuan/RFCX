{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RFCX_train_from_npy_image_v1_6_.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "t3l_5_WXkHrd"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ITzFStSplR82"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MMoGy2fAk8Sa"
      },
      "source": [
        "%%time\n",
        "# 大体10分くらい\n",
        "\n",
        "!pip install -q kaggle\n",
        "!mkdir -p .kaggle\n",
        "!cp \"./drive/My Drive/Study/config/kaggle.json\" .kaggle/\n",
        "!chmod 600 .kaggle/kaggle.json\n",
        "!mv .kaggle /root\n",
        "\n",
        "!kaggle datasets download \"theoviel/rcfx-spectrograms-32-khz\"\n",
        "!unzip rcfx-spectrograms-32-khz.zip > /dev/null\n",
        "!rm -rf rcfx-spectrograms-32-khz.zip \n",
        "\n",
        "!pip install -U iterative-stratification albumentations wandb  > /dev/null\n",
        "!wandb login e0792bb688a0d18e359df7438c45da90f8794091"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3zAeTPFiliqi"
      },
      "source": [
        "import os\n",
        "import tqdm\n",
        "import random\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n",
        "from datetime import datetime\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from numpy.random import beta\n",
        "\n",
        "import torch\n",
        "from torchvision.models import resnet18\n",
        "import torch.nn as nn\n",
        "from torch.optim import Adam, AdamW\n",
        "from torch.optim.lr_scheduler import CosineAnnealingLR, ReduceLROnPlateau\n",
        "from torchvision import transforms\n",
        "from torch.nn import functional as F\n",
        "\n",
        "import albumentations as A\n",
        "\n",
        "import wandb\n",
        "\n",
        "device = torch.device(\"cuda\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HCDqE-MXlkkz"
      },
      "source": [
        "DATA_ROOT = \"./drive/MyDrive/Study/RFCX/input\"\n",
        "\n",
        "sample_submission = pd.read_csv(f\"{DATA_ROOT}/sample_submission.csv\")\n",
        "train_fp = pd.read_csv(f\"{DATA_ROOT}/train_fp.csv\")\n",
        "train_tp = pd.read_csv(f\"{DATA_ROOT}/train_tp.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oOaTynrbBvi3"
      },
      "source": [
        "def get_label_and_middle_posi(_recording_id):\n",
        "    middle = []\n",
        "    #label = np.zeros((24, 128, 3751))\n",
        "    label = np.zeros((24, 3751))\n",
        "    for species_id, t_min, f_min, t_max, f_max in tp_dict[_recording_id]:\n",
        "        h, t = int(3751*(t_min/60)), int(3751*(t_max/60))\n",
        "        #d, u = int(128*f_min/16000), int(128*f_max/16000)\n",
        "        #label[species_id, d:u, h:t] = 1\n",
        "        label[species_id, h:t] = 1\n",
        "        m = (t + h)//2\n",
        "        middle.append(m)\n",
        "    return label, middle\n",
        "\n",
        "def get_label_and_middle_nega(_recording_id):\n",
        "    middle = []\n",
        "    #label = np.zeros((24, 128, 3751))\n",
        "    label = np.zeros((24, 3751))\n",
        "    for species_id, t_min, f_min, t_max, f_max in fp_dict[_recording_id]:\n",
        "        h, t = int(3751*(t_min/60)), int(3751*(t_max/60))\n",
        "        m = (t + h)//2\n",
        "        middle.append(m)\n",
        "    return label, middle\n",
        "\n",
        "counts_df = train_tp[\"species_id\"].value_counts()\n",
        "max_counts = counts_df.max()\n",
        "label_weight = max_counts / counts_df\n",
        "pos_weights = torch.Tensor(label_weight.sort_index().values).to(device)\n",
        "\n",
        "tp_dict = {}\n",
        "for recording_id, df in train_tp.groupby(\"recording_id\"):\n",
        "    tp_dict[recording_id] = df.values[:, [1,3,4,5,6]]\n",
        "\n",
        "fp_dict = {}\n",
        "for recording_id, df in train_fp.groupby(\"recording_id\"):\n",
        "    fp_dict[recording_id+\"_nega\"] = df.values[:, [1,3,4,5,6]]\n",
        "\n",
        "fnames, labels = [], []\n",
        "for recording_id, df in train_tp.groupby(\"recording_id\"):\n",
        "    v = sum([np.eye(24)[i] for i in df[\"species_id\"].tolist()])\n",
        "    v = (v  == 1).astype(int).tolist()\n",
        "    fnames.append(recording_id)\n",
        "    labels.append(v)\n",
        "\n",
        "fnames = np.array(fnames)\n",
        "labels = np.array(labels)\n",
        "fp_id_list = [lab+\"_nega\" for lab in train_fp[\"recording_id\"].unique()]\n",
        "test_fnames = sample_submission[\"recording_id\"].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kv4tt5lLl03a"
      },
      "source": [
        "# https://www.kaggle.com/c/rfcx-species-audio-detection/discussion/198418\n",
        "\n",
        "# LRAP. Instance-level average\n",
        "# Assume float preds [BxC], labels [BxC] of 0 or 1\n",
        "def LRAP(preds, labels):\n",
        "    # Ranks of the predictions\n",
        "    ranked_classes = torch.argsort(preds, dim=-1, descending=True)\n",
        "    # i, j corresponds to rank of prediction in row i\n",
        "    class_ranks = torch.zeros_like(ranked_classes)\n",
        "    for i in range(ranked_classes.size(0)):\n",
        "        for j in range(ranked_classes.size(1)):\n",
        "            class_ranks[i, ranked_classes[i][j]] = j + 1\n",
        "    # Mask out to only use the ranks of relevant GT labels\n",
        "    ground_truth_ranks = class_ranks * labels + (1e6) * (1 - labels)\n",
        "    # All the GT ranks are in front now\n",
        "    sorted_ground_truth_ranks, _ = torch.sort(ground_truth_ranks, dim=-1, descending=False)\n",
        "    pos_matrix = torch.tensor(np.array([i+1 for i in range(labels.size(-1))])).unsqueeze(0)\n",
        "    score_matrix = pos_matrix / sorted_ground_truth_ranks\n",
        "    score_mask_matrix, _ = torch.sort(labels, dim=-1, descending=True)\n",
        "    scores = score_matrix * score_mask_matrix\n",
        "    score = (scores.sum(-1) / labels.sum(-1)).mean()\n",
        "    return score.item()\n",
        "\n",
        "# label-level average\n",
        "# Assume float preds [BxC], labels [BxC] of 0 or 1\n",
        "def LWLRAP(preds, labels):\n",
        "    # Ranks of the predictions\n",
        "    ranked_classes = torch.argsort(preds, dim=-1, descending=True)\n",
        "    # i, j corresponds to rank of prediction in row i\n",
        "    class_ranks = torch.zeros_like(ranked_classes)\n",
        "    for i in range(ranked_classes.size(0)):\n",
        "        for j in range(ranked_classes.size(1)):\n",
        "            class_ranks[i, ranked_classes[i][j]] = j + 1\n",
        "    # Mask out to only use the ranks of relevant GT labels\n",
        "    ground_truth_ranks = class_ranks * labels + (1e6) * (1 - labels)\n",
        "    # All the GT ranks are in front now\n",
        "    sorted_ground_truth_ranks, _ = torch.sort(ground_truth_ranks, dim=-1, descending=False)\n",
        "    # Number of GT labels per instance\n",
        "    num_labels = labels.sum(-1)\n",
        "    pos_matrix = torch.tensor(np.array([i+1 for i in range(labels.size(-1))])).unsqueeze(0)\n",
        "    score_matrix = pos_matrix / sorted_ground_truth_ranks\n",
        "    score_mask_matrix, _ = torch.sort(labels, dim=-1, descending=True)\n",
        "    scores = score_matrix * score_mask_matrix\n",
        "    score = scores.sum() / labels.sum()\n",
        "    return score.item()\n",
        "\n",
        "def set_seed(seed: int = 42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)  # type: ignore\n",
        "    torch.backends.cudnn.deterministic = True  # type: ignore\n",
        "    torch.backends.cudnn.benchmark = True  # type: ignore\n",
        "\n",
        "def parse_labels(recording_id):\n",
        "    try:\n",
        "        label = label_dict[recording_id]\n",
        "    except KeyError:\n",
        "        label = np.zeros(24)\n",
        "    return label\n",
        "\n",
        "def mixup(input, gamma, perm):\n",
        "    perm_input = input[perm]\n",
        "    return input.mul_(gamma).add_(1 - gamma, perm_input)\n",
        "\n",
        "def interpolate(x: torch.Tensor, ratio: int):\n",
        "    x = x.transpose(1, 2)\n",
        "    (batch_size, time_steps, classes_num) = x.shape\n",
        "    upsampled = x[:, :, None, :].repeat(1, 1, ratio, 1)\n",
        "    upsampled = upsampled.reshape(batch_size, time_steps * ratio, classes_num)\n",
        "    upsampled = upsampled.transpose(1, 2)\n",
        "    return upsampled"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZzKRUeO9lqA4"
      },
      "source": [
        "class TimeMask:\n",
        "    def __init__(self, T=40, num_masks=1, replace_with_zero=True):\n",
        "        self.T = T\n",
        "        self.num_masks = num_masks\n",
        "        self.replace_with_zero = replace_with_zero\n",
        "\n",
        "    def __call__(self, spec):\n",
        "        cloned = spec.clone()\n",
        "        len_spectro = cloned.shape[2]\n",
        "    \n",
        "        for i in range(0, self.num_masks):\n",
        "            t = random.randrange(0, self.T)\n",
        "            t_zero = random.randrange(0, len_spectro - t)\n",
        "\n",
        "            # avoids randrange error if values are equal and range is empty\n",
        "            if (t_zero == t_zero + t): return cloned\n",
        "\n",
        "            mask_end = random.randrange(t_zero, t_zero + t)\n",
        "            if (self.replace_with_zero): cloned[:,:,t_zero:mask_end] = 0\n",
        "            else: cloned[:,:,t_zero:mask_end] = cloned.mean()\n",
        "        return cloned\n",
        "\n",
        "class FreqMask:\n",
        "    def __init__(self, F=30, num_masks=1, replace_with_zero=True):\n",
        "        self.F = F\n",
        "        self.num_masks = num_masks\n",
        "        self.replace_with_zero = replace_with_zero\n",
        "\n",
        "    def __call__(self, spec):\n",
        "        cloned = spec.clone()\n",
        "        num_mel_channels = cloned.shape[1]\n",
        "    \n",
        "        for i in range(0, self.num_masks):        \n",
        "            f = random.randrange(0, self.F)\n",
        "            f_zero = random.randrange(0, num_mel_channels - f)\n",
        "\n",
        "            # avoids randrange error if values are equal and range is empty\n",
        "            if (f_zero == f_zero + f): return cloned\n",
        "\n",
        "            mask_end = random.randrange(f_zero, f_zero + f) \n",
        "            if (self.replace_with_zero): cloned[:, f_zero:mask_end] = 0\n",
        "            else: cloned[:, f_zero:mask_end] = cloned.mean()\n",
        "    \n",
        "        return cloned\n",
        "\n",
        "def mono_to_color(\n",
        "    X: np.ndarray, mean=None, std=None,\n",
        "    norm_max=None, norm_min=None, eps=1e-6\n",
        "):\n",
        "    # Stack X as [X,X,X]\n",
        "    X = np.stack([X, X, X], axis=-1)\n",
        "\n",
        "    # Standardize\n",
        "    mean = mean or X.mean()\n",
        "    X = X - mean\n",
        "    std = std or X.std()\n",
        "    Xstd = X / (std + eps)\n",
        "    _min, _max = Xstd.min(), Xstd.max()\n",
        "    norm_max = norm_max or _max\n",
        "    norm_min = norm_min or _min\n",
        "    if (_max - _min) > eps:\n",
        "        # Normalize to [0, 255]\n",
        "        V = Xstd\n",
        "        V[V < norm_min] = norm_min\n",
        "        V[V > norm_max] = norm_max\n",
        "        V = 255 * (V - norm_min) / (norm_max - norm_min)\n",
        "        V = V.astype(np.uint8)\n",
        "    else:\n",
        "        # Just zero\n",
        "        V = np.zeros_like(Xstd, dtype=np.uint8)\n",
        "    return V\n",
        "\n",
        "H_POS = [32, 64, 128, 256]\n",
        "WINDOW = 512\n",
        "#H_POS = [32, 64, 128]\n",
        "#WINDOW = 256\n",
        "MAX_SEQ = 3751 - 1\n",
        "def extract_ht_pos(pos):\n",
        "    h_pos = [p for p in H_POS if (pos - p) > 0]\n",
        "    if len(h_pos) > 0:\n",
        "        h_pos = random.choice(h_pos)\n",
        "    else:\n",
        "        h_pos = pos\n",
        "    t_pos = WINDOW - h_pos\n",
        "    h, t = pos-h_pos, pos+t_pos\n",
        "    if t > MAX_SEQ:\n",
        "        h, t = MAX_SEQ-WINDOW, MAX_SEQ\n",
        "    return h, t\n",
        "\n",
        "class SpectrogramFromNpz(torch.utils.data.Dataset):\n",
        "    def __init__(self, fname, mode):\n",
        "        self.fname = fname\n",
        "        self.mode = mode\n",
        "        self.to_tensor = transforms.ToTensor()\n",
        "        self.norm = transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
        "        self.augument_funcs_a = A.Compose([\n",
        "            A.RandomBrightnessContrast(p=0.5)\n",
        "        ])\n",
        "        self.augument_funcs_b = transforms.RandomApply([\n",
        "            transforms.Lambda(lambda img: transforms.functional.adjust_gamma(img, gamma=2, gain=1)),\n",
        "            TimeMask(),\n",
        "            FreqMask(),\n",
        "        ], p=0.5)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.fname)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        fname = self.fname[idx]\n",
        "\n",
        "        # load labels\n",
        "        try:\n",
        "            label, middle = get_label_and_middle_posi(fname)\n",
        "            pos = random.choice(middle)\n",
        "            h, t = extract_ht_pos(pos)\n",
        "        except KeyError:\n",
        "            try:\n",
        "                label, middle = get_label_and_middle_nega(fname)\n",
        "                pos = random.choice(middle)\n",
        "                h, t = extract_ht_pos(pos)\n",
        "            except KeyError:\n",
        "                label, h, t = None, None, None\n",
        "        if self.mode == \"train\":\n",
        "            #label = label[:, :, h:t]\n",
        "            label = label[:, h:t]\n",
        "        \n",
        "        # load images\n",
        "        if self.mode in [\"train\", \"valid\"]:\n",
        "            if \"_nega\" in fname:\n",
        "                _fname = fname.replace(\"_nega\", \"\")\n",
        "                path = f\"./train/{_fname}.npy\"\n",
        "            else:\n",
        "                path = f\"./train/{fname}.npy\"\n",
        "        elif self.mode == \"test\":\n",
        "            path = f\"./test/{fname}.npy\"\n",
        "        mel = np.load(path)\n",
        "        image = mono_to_color(mel)\n",
        "\n",
        "        # augument\n",
        "        if self.mode == \"train\":\n",
        "            image = self.augument_funcs_a(image=image)[\"image\"]\n",
        "            image = self.to_tensor(image)\n",
        "            image = self.augument_funcs_b(image)\n",
        "            image = image[:, :, h:t]\n",
        "        else:\n",
        "            image = self.to_tensor(image)\n",
        "        image = self.norm(image)\n",
        "\n",
        "        return image, label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nDWcvxkKl70K"
      },
      "source": [
        "pred_w = [0.4, 0.4, 0.1, 0.1]\n",
        "\n",
        "def rfcx_criterion(outputs, targets):\n",
        "    # prediction\n",
        "    ## time pool\n",
        "    pseudo_label_ti = outputs[\"pseudo_label_ti\"]\n",
        "    clipwise_preds_att_ti = outputs[\"clipwise_preds_att_ti\"]\n",
        "    attention_preds_ti = outputs[\"attention_preds_ti\"]\n",
        "    clipwise_preds_max_ti = outputs[\"clipwise_preds_max_ti\"]\n",
        "    segmentwise_output_ti = outputs[\"segmentwise_output_ti\"]\n",
        "    ## Hz pool\n",
        "    #pseudo_label_hz = outputs[\"pseudo_label_hz\"]\n",
        "    #clipwise_preds_att_hz = outputs[\"clipwise_preds_att_hz\"]\n",
        "    #attention_preds_hz = outputs[\"attention_preds_hz\"]\n",
        "    #clipwise_preds_max_hz = outputs[\"clipwise_preds_max_hz\"]\n",
        "    #segmentwise_output_hz = outputs[\"segmentwise_output_hz\"]\n",
        "\n",
        "    # target\n",
        "    #clip_y, seq_y, hz_y = targets\n",
        "    clip_y, seq_y = targets\n",
        "\n",
        "    # loss\n",
        "    ## clip wise att\n",
        "    loss1_ti = nn.BCEWithLogitsLoss(pos_weight=pos_weights)(clipwise_preds_att_ti, clip_y)\n",
        "    #loss1_hz = nn.BCEWithLogitsLoss(pos_weight=pos_weights)(clipwise_preds_att_hz, clip_y)\n",
        "    #loss1 = loss1_ti + loss1_hz*0.25\n",
        "    ## clip wise max\n",
        "    loss2_ti = nn.BCEWithLogitsLoss(pos_weight=pos_weights)(clipwise_preds_max_ti, clip_y)\n",
        "    #loss2_hz = nn.BCEWithLogitsLoss(pos_weight=pos_weights)(clipwise_preds_max_hz, clip_y)\n",
        "    #loss2 = loss2_ti + loss2_hz*0.25\n",
        "    ## pseudo wise\n",
        "    loss3_ti = nn.BCEWithLogitsLoss(reduction=\"none\")(attention_preds_ti, pseudo_label_ti)\n",
        "    loss3_ti = (loss3_ti.mean(2) * pos_weights).mean()\n",
        "    #loss3_hz = nn.BCEWithLogitsLoss(reduction=\"none\")(attention_preds_hz, pseudo_label_hz)\n",
        "    #loss3_hz = (loss3_hz.mean(2) * pos_weights).mean()\n",
        "    #loss3 = loss3_ti + loss3_hz*0.25\n",
        "    ## seq or Hz wise\n",
        "    loss4_ti = nn.BCEWithLogitsLoss(reduction=\"none\")(segmentwise_output_ti, seq_y)\n",
        "    loss4_ti = (loss4_ti.mean(2) * pos_weights).mean()\n",
        "    #loss4_hz = nn.BCEWithLogitsLoss(reduction=\"none\")(segmentwise_output_hz, hz_y)\n",
        "    #loss4_hz = (loss4_hz.mean(2) * pos_weights).mean()\n",
        "    #loss4 = (loss4_ti + loss4_hz) / 2\n",
        "\n",
        "    #loss = loss1 + loss2*0.5 + loss3 + loss4*0.5\n",
        "    #loss = (loss1_ti + loss2_ti + loss3_ti + loss4_ti) / 4\n",
        "    #loss = loss1 + loss2*0.5 + loss3 + loss4_ti*0.5\n",
        "    loss = loss1_ti + loss2_ti*0.5 + loss3_ti + loss4_ti*0.5\n",
        "\n",
        "    return loss\n",
        "\n",
        "\n",
        "def train_loop(train_data_loader, model, optimizer, scheduler):\n",
        "    model.train()\n",
        "    losses, lrs = [], []\n",
        "    for X, y in train_data_loader:\n",
        "        \n",
        "        X = X.to(device)\n",
        "        #clip_y = (y.sum((2, 3)) != 0).float().to(device)\n",
        "        #seq_y = (y.sum(2) != 0).float().to(device)\n",
        "        #hz_y = (y.sum(3) != 0).float().to(device)\n",
        "        clip_y = (y.sum(2) != 0).float().to(device)\n",
        "        seq_y = y.to(device)\n",
        "\n",
        "        # mixup\n",
        "        b = beta(0.1, 0.1)\n",
        "        perm = torch.randperm(X.size(0))\n",
        "        X = mixup(X, b, perm)\n",
        "        clip_y = mixup(clip_y, b, perm)\n",
        "        seq_y = mixup(seq_y, b, perm)\n",
        "        #hz_y = mixup(hz_y, b, perm)\n",
        "\n",
        "        outputs = model(X)\n",
        "        #loss = rfcx_criterion(outputs, (clip_y, seq_y, hz_y))\n",
        "        loss = rfcx_criterion(outputs, (clip_y, seq_y))\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if scheduler is not None:\n",
        "            scheduler.step()\n",
        "\n",
        "        losses.append(loss.item())\n",
        "        lrs.append(np.array([param_group[\"lr\"] for param_group in optimizer.param_groups]).mean())\n",
        "    t_loss = np.array(losses).mean()\n",
        "    lr =  np.array(lrs).mean()\n",
        "    return t_loss, lr\n",
        "\n",
        "eval_img_pos = [[0, WINDOW]]\n",
        "for idx in range(1, 8):\n",
        "#for idx in range(1, 18):\n",
        "    h, t = eval_img_pos[idx-1][0], eval_img_pos[idx-1][1]\n",
        "    h = t - 51\n",
        "    #h = t - 50\n",
        "    t = h + WINDOW\n",
        "    eval_img_pos.append([h, t])\n",
        "    \n",
        "def valid_loop(valid_data_loader, model):\n",
        "    model.eval()\n",
        "    v_scores, v_losses = [], []\n",
        "    for X, y in valid_data_loader:\n",
        "        X = X.to(device)\n",
        "        #clip_y = (y.sum((2, 3)) != 0).float().to(device)\n",
        "        #seq_y = (y.sum(2) != 0).float().to(device)\n",
        "        #hz_y = (y.sum(3) != 0).float().to(device)\n",
        "        clip_y = (y.sum(2) != 0).float().to(device)\n",
        "        seq_y = y.to(device)\n",
        "\n",
        "        preds = []\n",
        "        for h, t in eval_img_pos:\n",
        "            with torch.no_grad():\n",
        "                outputs = model(X)\n",
        "            p1 = outputs[\"clipwise_preds_att_ti\"].sigmoid() #* pred_w[0]\n",
        "            p2 = outputs[\"clipwise_preds_max_ti\"].sigmoid() #* pred_w[1]\n",
        "            #p3 = outputs[\"clipwise_preds_att_hz\"].sigmoid() * pred_w[2]\n",
        "            #p4 = outputs[\"clipwise_preds_max_hz\"].sigmoid() * pred_w[3]\n",
        "            #pred = p1 + p2 + p3 + p4\n",
        "            pred = (p1 + p2)/2\n",
        "            preds.append(pred)\n",
        "        max_pred, _  = torch.max(torch.stack(preds), dim=0)\n",
        "\n",
        "        score = LRAP(max_pred.cpu(), clip_y.cpu())\n",
        "        #loss = rfcx_criterion(outputs, (clip_y, seq_y, hz_y))\n",
        "        loss = nn.BCEWithLogitsLoss(pos_weight=pos_weights)(max_pred, clip_y).cpu().numpy()\n",
        "        v_scores.append(score)\n",
        "        v_losses.append(loss.item())\n",
        "\n",
        "    valid_score, valid_loss = np.array(v_scores).mean(), np.array(v_losses).mean()\n",
        "    return valid_score, valid_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p3Ka8mxKmCka"
      },
      "source": [
        "class RFCXNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(RFCXNet, self).__init__()\n",
        "        self.n_label = 24\n",
        "        resnet = resnet18(pretrained=True)\n",
        "        self.resnet_head = nn.Sequential(*list(resnet.children())[:-2])\n",
        "\n",
        "        self.fc_a = nn.Conv1d(512, self.n_label, 1, bias=False)\n",
        "        self.fc_b = nn.Conv1d(512, self.n_label, 1, bias=False)\n",
        "        #self.fc_c = nn.Conv1d(512, self.n_label, 1, bias=False)\n",
        "        #self.fc_d = nn.Conv1d(512, self.n_label, 1, bias=False)\n",
        "\n",
        "    def forward(self, x, perm=None, gamma=None):  # input x: (batch, channel, Hz, time)\n",
        "        frames_num = x.shape[3]\n",
        "        x = x.transpose(3, 2)  # (batch, channel, time, Hz)\n",
        "\n",
        "        h = self.resnet_head(x)  # (batch, unit, time, Hz)\n",
        "        if perm is not None:\n",
        "            h = gamma * h + (1 - gamma) * h[perm]\n",
        "        \n",
        "        h = F.relu(h)\n",
        "        ti_pool = torch.mean(h, dim=3)  # (batch, unit, time)\n",
        "        #hz_pool = torch.mean(h, dim=2)  # (batch, unit, Hz)\n",
        "        \n",
        "        xa = self.fc_a(ti_pool)  # (batch, n_class, time)\n",
        "        xb = self.fc_b(ti_pool)  # (batch, n_class, time)\n",
        "        xb = torch.softmax(xb, dim=2)\n",
        "\n",
        "        #xc = self.fc_c(hz_pool)  # (batch, n_class, Hz)\n",
        "        #xd = self.fc_d(hz_pool)  # (batch, n_class, Hz)\n",
        "        #xd = torch.softmax(xd, dim=2)\n",
        "\n",
        "        # time pool\n",
        "        pseudo_label_ti = (xa.sigmoid() >= 0.7).float()\n",
        "        clipwise_preds_att_ti = torch.sum(xa * xb, dim=2)\n",
        "        clipwise_preds_max_ti, _ = torch.max(xa, dim=2)\n",
        "        attention_preds_ti = xb\n",
        "        segmentwise_output_ti = interpolate(xa, 32)\n",
        "\n",
        "        # Hz pool\n",
        "        #pseudo_label_hz = (xc.sigmoid() >= 0.7).float()\n",
        "        #clipwise_preds_att_hz = torch.sum(xc * xd, dim=2)\n",
        "        #clipwise_preds_max_hz, _ = torch.max(xc, dim=2)\n",
        "        #attention_preds_hz = xd\n",
        "        #segmentwise_output_hz = interpolate(xc*xd, 32)\n",
        "\n",
        "        return {\n",
        "            \"pseudo_label_ti\": pseudo_label_ti,\n",
        "            \"clipwise_preds_att_ti\": clipwise_preds_att_ti,\n",
        "            \"attention_preds_ti\": attention_preds_ti,\n",
        "            \"clipwise_preds_max_ti\": clipwise_preds_max_ti,\n",
        "            \"segmentwise_output_ti\": segmentwise_output_ti,\n",
        "            #\"pseudo_label_hz\": pseudo_label_hz,\n",
        "            #\"clipwise_preds_att_hz\": clipwise_preds_att_hz,\n",
        "            #\"attention_preds_hz\": attention_preds_hz,\n",
        "            #\"clipwise_preds_max_hz\": clipwise_preds_max_hz,\n",
        "            #\"segmentwise_output_hz\": segmentwise_output_hz,\n",
        "        }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g9aw5dYm-3v_"
      },
      "source": [
        "\"\"\"model = RFCXNet()\n",
        "model.to(device)\n",
        "\n",
        "train_datasets = SpectrogramFromNpz(fnames, \"train\")\n",
        "train_data_loader = torch.utils.data.DataLoader(train_datasets, batch_size=4, shuffle=True, num_workers=0)\n",
        "\n",
        "for X, y in train_data_loader:\n",
        "    clip_y = (y.sum((2, 3)) != 0).float().to(device)\n",
        "    seq_y = (y.sum(2) != 0).float().to(device)\n",
        "    hz_y = (y.sum(3) != 0).float().to(device)\n",
        "\n",
        "    output = model(X.to(device))\n",
        "    loss = rfcx_criterion(output, (clip_y, seq_y, hz_y))\n",
        "    break\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c8xtDWjwPpLN"
      },
      "source": [
        "SEED = 416\n",
        "N_FOLD = 5\n",
        "WORKS = 0\n",
        "EXP_NAME = \"exp0048_fix_nega_label\"\n",
        "OUTPUT = f\"./drive/MyDrive/Study/RFCX/output/{EXP_NAME}\"\n",
        "\n",
        "!mkdir -p {OUTPUT}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7bBbq5JIx6E2"
      },
      "source": [
        "mskf = MultilabelStratifiedKFold(n_splits=5, shuffle=True, random_state=0)\n",
        "test_datasets = SpectrogramFromNpz(test_fnames, \"test\")\n",
        "\n",
        "for fold, (train_index, valid_index) in enumerate(mskf.split(fnames, labels)):\n",
        "    #if fold in [0, 1, 2, 3]:\n",
        "    #    continue\n",
        "    print(datetime.now(), f\"\\t: ### FOLD-{fold} ###\")\n",
        "    set_seed(SEED)\n",
        "    wandb.init(project=\"rfcx\", name=f\"{EXP_NAME}_f{fold}\")\n",
        "\n",
        "    # hyper parameter\n",
        "    config = wandb.config\n",
        "    config.seed = 416\n",
        "    config.learning_rate = 1e-3\n",
        "    config.batch_size = 64\n",
        "    config.num_epochs = 50\n",
        "    config.alpha = 0.1\n",
        "    config.t_max = 10\n",
        "    config.factor = 0.5\n",
        "\n",
        "    config.exp_name = EXP_NAME\n",
        "    config.fold = fold\n",
        "\n",
        "    train_fname = fnames[train_index]\n",
        "    valid_fname = fnames[valid_index]\n",
        "\n",
        "    fp_fnames = random.sample(fp_id_list, 50)\n",
        "    train_datasets = SpectrogramFromNpz(train_fname.tolist()+fp_fnames, \"train\")\n",
        "    train_data_loader = torch.utils.data.DataLoader(train_datasets, batch_size=config.batch_size, shuffle=True, num_workers=WORKS)\n",
        "    valid_datasets = SpectrogramFromNpz(valid_fname, \"valid\")\n",
        "    valid_data_loader = torch.utils.data.DataLoader(valid_datasets, batch_size=config.batch_size, shuffle=False, num_workers=WORKS)\n",
        "\n",
        "    model = RFCXNet()\n",
        "    model.to(device)\n",
        "    optimizer = Adam(model.parameters(), lr=config.learning_rate)\n",
        "    \n",
        "    scheduler = CosineAnnealingLR(optimizer, T_max=len(train_data_loader)*config.t_max, eta_min=0.0)\n",
        "    del train_datasets, train_data_loader\n",
        "\n",
        "    wandb.watch(model)\n",
        "\n",
        "    print(datetime.now(), \"\\t: start train\")\n",
        "    best_score, best_loss = 0, 9999\n",
        "    for epoch in range(config.num_epochs):\n",
        "        fp_fnames = random.sample(fp_id_list, 50)\n",
        "        train_datasets = SpectrogramFromNpz(train_fname.tolist()+fp_fnames, \"train\")\n",
        "        train_data_loader = torch.utils.data.DataLoader(train_datasets, batch_size=config.batch_size, shuffle=True, num_workers=WORKS)\n",
        "\n",
        "        t_loss, lr = train_loop(train_data_loader, model, optimizer, scheduler)\n",
        "        v_score, v_loss = valid_loop(valid_data_loader, model)\n",
        "    \n",
        "        if best_score < v_score:\n",
        "            print(f\"epoch {epoch}: best score update !!!\")\n",
        "            torch.save(model.state_dict(), f\"{OUTPUT}/rfcxnet_f{config.fold}_best_score_model.bin\")\n",
        "            best_score = v_score\n",
        "        if best_loss > v_loss:\n",
        "            print(f\"epoch {epoch}: best loss update !!!\")\n",
        "            torch.save(model.state_dict(), f\"{OUTPUT}/rfcxnet_f{config.fold}_best_loss_model.bin\")\n",
        "            best_loss = v_loss\n",
        "    \n",
        "        wandb.log({\"train loss\": t_loss, \"lr\": lr, \"valid loss\": v_loss, \"valid score\": v_score, \"best score\": best_score, \"best loss\": best_loss})\n",
        "    print(datetime.now(), \"\\t: finish train\")\n",
        "\n",
        "    # predict test data\n",
        "    model.load_state_dict(torch.load(f\"{OUTPUT}/rfcxnet_f{config.fold}_best_score_model.bin\"))\n",
        "\n",
        "    lst = []\n",
        "    for idx, (X, _) in tqdm.tqdm_notebook(enumerate(test_datasets), total=1992):\n",
        "        preds = []\n",
        "        for h, t in eval_img_pos:\n",
        "            with torch.no_grad():\n",
        "                outputs = model(X[:,:,h:t].unsqueeze(0).to(device))\n",
        "            p1 = outputs[\"clipwise_preds_att_ti\"].sigmoid() #* pred_w[0]\n",
        "            p2 = outputs[\"clipwise_preds_max_ti\"].sigmoid() #* pred_w[1]\n",
        "            #p3 = outputs[\"clipwise_preds_att_hz\"].sigmoid() * pred_w[2]\n",
        "            #p4 = outputs[\"clipwise_preds_max_hz\"].sigmoid() * pred_w[3]\n",
        "            #pred = (p1 + p2 + p3 + p4) / 4\n",
        "            pred = (p1 + p2)/2\n",
        "            #pred = p2\n",
        "            preds.append(pred)\n",
        "        max_pred, _  = torch.max(torch.stack(preds), dim=0)\n",
        "        pred = max_pred.cpu().numpy()[0].tolist()\n",
        "\n",
        "        row = [test_fnames[idx]] + pred\n",
        "        lst.append(row)\n",
        "\n",
        "    fold_sub = pd.DataFrame(lst, columns=[\"recording_id\"]+[f\"s{i}\" for i in range(24)])\n",
        "    fold_sub.to_csv(f\"{OUTPUT}/rfcxnet_f{config.fold}_predict.csv\", index=None)\n",
        "wandb.init()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HVIWrH5kEN7i"
      },
      "source": [
        "#import pandas as pd\n",
        "#import torch\n",
        "#!ls ./drive/MyDrive/Study/RFCX/output/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2B8DthnrYnYC"
      },
      "source": [
        "#EXP_NAME = \"exp0043_segmentwise_axb\"\n",
        "#OUTPUT = f\"./drive/MyDrive/Study/RFCX/output/{EXP_NAME}\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bOR0_hcSoVC_"
      },
      "source": [
        "all_v_lst = []\n",
        "for fold in range(5):\n",
        "    df = pd.read_csv(f\"{OUTPUT}/rfcxnet_f{fold}_predict.csv\")\n",
        "    ids, v_lst = [], []\n",
        "    for row in df.values:\n",
        "        recording_id = row[0]\n",
        "        ids.append(recording_id)\n",
        "        v = torch.Tensor(row[1:].astype(float))\n",
        "        v_lst.append(v)\n",
        "    all_v_lst.append(torch.stack(v_lst, axis=0))\n",
        "\n",
        "all_preds = torch.stack(all_v_lst, axis=2).mean(2)\n",
        "sub = pd.DataFrame(all_preds.tolist(), columns=df.columns[1:])\n",
        "sub = pd.concat([df[[\"recording_id\"]], sub], axis=1)\n",
        "sub.to_csv(f\"./submission_{EXP_NAME}.csv\", index=None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qmh8Vfikp6NZ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}