{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RFCX_Make_OOF.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "8rHRtb7BRkIk"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oybEhVOsRp82"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jqgBWtNARu0C"
      },
      "source": [
        "%%time\n",
        "# 大体10分くらい\n",
        "\n",
        "!pip install -q kaggle\n",
        "!mkdir -p .kaggle\n",
        "!cp \"./drive/My Drive/Study/config/kaggle.json\" .kaggle/\n",
        "!chmod 600 .kaggle/kaggle.json\n",
        "!mv .kaggle /root\n",
        "\n",
        "!kaggle datasets download \"theoviel/rcfx-spectrograms-32-khz\"\n",
        "!unzip rcfx-spectrograms-32-khz.zip > /dev/null\n",
        "!rm -rf rcfx-spectrograms-32-khz.zip \n",
        "\n",
        "!pip install -U iterative-stratification albumentations wandb  > /dev/null\n",
        "!wandb login e0792bb688a0d18e359df7438c45da90f8794091\n",
        "\n",
        "!pip install timm\n",
        "!pip install imbalanced-learn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F3v6_JDwRz47"
      },
      "source": [
        "import gc\n",
        "import os\n",
        "import tqdm\n",
        "import random\n",
        "import pickle\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n",
        "from datetime import datetime\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from numpy.random import beta\n",
        "\n",
        "import torch\n",
        "from torchvision.models import resnet18, densenet121\n",
        "import torch.nn as nn\n",
        "from torch.optim import Adam, AdamW\n",
        "from torch.optim.lr_scheduler import CosineAnnealingLR, ReduceLROnPlateau, CosineAnnealingWarmRestarts\n",
        "from torchvision import transforms\n",
        "from torch.nn import functional as F\n",
        "\n",
        "import albumentations as A\n",
        "\n",
        "from sklearn.metrics import classification_report, roc_auc_score\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "import wandb\n",
        "import timm\n",
        "\n",
        "device = torch.device(\"cuda\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r2u0OiZmR3At"
      },
      "source": [
        "EXP = \"exp0127_resnet18_second_st_only_label_loss\"\n",
        "BEST_MODEL = f\"./drive/MyDrive/Study/RFCX/output/{EXP}\"\n",
        "DATA_ROOT = \"./drive/MyDrive/Study/RFCX/input\"\n",
        "\n",
        "PSEUDO_THR_P = 0.5\n",
        "PSEUDO_THR_N = 0.01\n",
        "SEED = 416\n",
        "\n",
        "MODEL_NAME = \"resnet18\"\n",
        "N_LABEL = 24\n",
        "N_SPLIT_IMG = 8\n",
        "WINDOW = 512\n",
        "COVER = 49"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SRQediqaR9IE"
      },
      "source": [
        "def mono_to_color(\n",
        "    X: np.ndarray, mean=None, std=None,\n",
        "    norm_max=None, norm_min=None, eps=1e-6\n",
        "):\n",
        "    # Stack X as [X,X,X]\n",
        "    X = np.stack([X, X, X], axis=-1)\n",
        "\n",
        "    # Standardize\n",
        "    mean = mean or X.mean()\n",
        "    X = X - mean\n",
        "    std = std or X.std()\n",
        "    Xstd = X / (std + eps)\n",
        "    _min, _max = Xstd.min(), Xstd.max()\n",
        "    norm_max = norm_max or _max\n",
        "    norm_min = norm_min or _min\n",
        "    if (_max - _min) > eps:\n",
        "        # Normalize to [0, 255]\n",
        "        V = Xstd\n",
        "        V[V < norm_min] = norm_min\n",
        "        V[V > norm_max] = norm_max\n",
        "        V = 255 * (V - norm_min) / (norm_max - norm_min)\n",
        "        V = V.astype(np.uint8)\n",
        "    else:\n",
        "        # Just zero\n",
        "        V = np.zeros_like(Xstd, dtype=np.uint8)\n",
        "    return V\n",
        "\n",
        "class SpectrogramFromNpz(torch.utils.data.Dataset):\n",
        "    def __init__(self, fname, mode):\n",
        "        self.fname = fname\n",
        "        self.mode = mode\n",
        "        self.to_tensor = transforms.ToTensor()\n",
        "        self.norm = transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.fname)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        fname = self.fname[idx]\n",
        "\n",
        "        # load image        \n",
        "        _fname = fname.replace(\"_posi\", \"\").replace(\"_nega\", \"\")\n",
        "        path = f\"./{self.mode}/{_fname}.npy\"\n",
        "        mel = np.load(path)\n",
        "        \n",
        "        image = mono_to_color(mel)\n",
        "        image = self.to_tensor(image)\n",
        "        image = self.norm(image)\n",
        "\n",
        "        return image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "clqFucIYSB8s"
      },
      "source": [
        "MODEL_HEADER_INFO = {\n",
        "    \"resnet18\": (-2, 512),\n",
        "    \"densenet121\": (-2, 1024),\n",
        "    \"efficientnet_b0\": (-5, 320),\n",
        "    \"resnest50d\": (-2, 2048),\n",
        "    \"mobilenetv2_100\": (-2, 1280),\n",
        "}\n",
        "\n",
        "def interpolate(x: torch.Tensor, ratio: int):\n",
        "    x = x.transpose(1, 2)\n",
        "    (batch_size, time_steps, classes_num) = x.shape\n",
        "    upsampled = x[:, :, None, :].repeat(1, 1, ratio, 1)\n",
        "    upsampled = upsampled.reshape(batch_size, time_steps * ratio, classes_num)\n",
        "    upsampled = upsampled.transpose(1, 2)\n",
        "    return upsampled\n",
        "\n",
        "class RFCXNet(nn.Module):\n",
        "    def __init__(self, model_name):\n",
        "        super(RFCXNet, self).__init__()\n",
        "        self.n_label = N_LABEL\n",
        "\n",
        "        base_model = timm.create_model(model_name, pretrained=True)\n",
        "        h_idx, n_dense = MODEL_HEADER_INFO[model_name]        \n",
        "\n",
        "        self.resnet_head = nn.Sequential(*list(base_model.children())[:h_idx])\n",
        "        \n",
        "        self.fc_a = nn.Conv1d(n_dense, self.n_label, 1, bias=False)\n",
        "        self.fc_b = nn.Conv1d(n_dense, self.n_label, 1, bias=False)\n",
        "\n",
        "    def forward(self, x, perm=None, gamma=None):  # input x: (batch, channel, Hz, time)\n",
        "        frames_num = x.shape[3]\n",
        "        x = x.transpose(3, 2)  # (batch, channel, time, Hz)\n",
        "\n",
        "        h = self.resnet_head(x)  # (batch, unit, time, Hz)\n",
        "\n",
        "        if perm is not None:\n",
        "            h = gamma * h + (1 - gamma) * h[perm]\n",
        "            \n",
        "        h = F.relu(h)\n",
        "        ti_pool = torch.mean(h, dim=3)  # (batch, unit, time)\n",
        "\n",
        "        xa = self.fc_a(ti_pool)  # (batch, n_class, time)\n",
        "        xb = self.fc_b(ti_pool)  # (batch, n_class, time)\n",
        "        xb = torch.softmax(xb, dim=2)\n",
        "\n",
        "        # time pool\n",
        "        clipwise_preds_att_ti = torch.sum(xa * xb, dim=2)\n",
        "        segmentwise_output_ti = interpolate(xa, 32)\n",
        "\n",
        "        return {\n",
        "            \"clipwise_preds_att_ti\": clipwise_preds_att_ti,\n",
        "            \"segmentwise_output_ti\": segmentwise_output_ti,\n",
        "        }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UoFrbMI7U9R9"
      },
      "source": [
        "def LWLRAP(preds, labels):\n",
        "    ranked_classes = torch.argsort(preds, dim=-1, descending=True)\n",
        "    class_ranks = torch.zeros_like(ranked_classes)\n",
        "    for i in range(ranked_classes.size(0)):\n",
        "        for j in range(ranked_classes.size(1)):\n",
        "            class_ranks[i, ranked_classes[i][j]] = j + 1\n",
        "    ground_truth_ranks = class_ranks * labels + (1e6) * (1 - labels)\n",
        "    sorted_ground_truth_ranks, _ = torch.sort(ground_truth_ranks, dim=-1, descending=False)\n",
        "    num_labels = labels.sum(-1)\n",
        "    pos_matrix = torch.tensor(np.array([i+1 for i in range(labels.size(-1))])).unsqueeze(0)\n",
        "    score_matrix = pos_matrix / sorted_ground_truth_ranks\n",
        "    score_mask_matrix, _ = torch.sort(labels, dim=-1, descending=True)\n",
        "    scores = score_matrix * score_mask_matrix\n",
        "    score = scores.sum() / labels.sum()\n",
        "    return score.item()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JiX7nhAHSEgs"
      },
      "source": [
        "train_fp = pd.read_csv(f\"{DATA_ROOT}/train_fp.csv\")\n",
        "train_tp = pd.read_csv(f\"{DATA_ROOT}/train_tp.csv\")\n",
        "\n",
        "tp_fnames, tp_labels = [], []\n",
        "for recording_id, df in train_tp.groupby(\"recording_id\"):\n",
        "    v = sum([np.eye(N_LABEL)[i] for i in df[\"species_id\"].tolist()])\n",
        "    v = (v  == 1).astype(int).tolist()\n",
        "    tp_fnames.append(recording_id+\"_posi\")\n",
        "    tp_labels.append(v)\n",
        "\n",
        "fp_fnames, fp_labels = [], []\n",
        "for recording_id, df in train_fp.groupby(\"recording_id\"):\n",
        "    v = sum([np.eye(N_LABEL)[i] for i in df[\"species_id\"].tolist()])\n",
        "    v = (v  == 1).astype(int).tolist()\n",
        "    fp_fnames.append(recording_id+\"_nega\")\n",
        "    fp_labels.append(v)\n",
        "\n",
        "model = RFCXNet(MODEL_NAME)\n",
        "model.to(device)\n",
        "\n",
        "slide_img_pos = [[0, WINDOW]]\n",
        "for idx in range(1, N_SPLIT_IMG):\n",
        "    h, t = slide_img_pos[idx-1][0], slide_img_pos[idx-1][1]\n",
        "    h = t - COVER\n",
        "    t = h + WINDOW\n",
        "    slide_img_pos.append([h, t])\n",
        "\n",
        "print(slide_img_pos)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2zM_UJ-4S3rM"
      },
      "source": [
        "# OOF"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XjPuzGlFS499"
      },
      "source": [
        "## Positive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CoDHkRkbSRwa"
      },
      "source": [
        "valid_preds_dfs = []\n",
        "scores = []\n",
        "tp_oof = np.zeros((len(tp_fnames), 8, 24))\n",
        "mskf = MultilabelStratifiedKFold(n_splits=5, shuffle=True, random_state=0)\n",
        "for fold, (train_index, valid_index) in enumerate(mskf.split(tp_fnames, tp_labels)):\n",
        "    valid_fnames = np.array(tp_fnames)[valid_index]\n",
        "\n",
        "    print(f\"### {fold} ###\")\n",
        "    model.load_state_dict(torch.load(f\"{BEST_MODEL}/rfcxnet_f{fold}_best_score_model.bin\"))\n",
        "    model.eval()\n",
        "\n",
        "    valid_dataset = SpectrogramFromNpz(valid_fnames, \"train\")\n",
        "    lst = []\n",
        "    for idx, X in tqdm.tqdm_notebook(enumerate(valid_dataset), total=len(valid_dataset)):\n",
        "        preds = []\n",
        "        for patch, (h, t) in enumerate(slide_img_pos):\n",
        "            with torch.no_grad():\n",
        "                outputs = model(X[:,:,h:t].unsqueeze(0).to(device))\n",
        "            pred = outputs[\"clipwise_preds_att_ti\"].sigmoid().cpu().numpy()[0]\n",
        "            row = [valid_fnames[idx], patch] + pred.tolist()\n",
        "            lst.append(row)\n",
        "\n",
        "    valid_preds_df = pd.DataFrame(lst, columns=[\"recording_id\", \"patch\"]+ [f\"s{i}\" for i in range(24)])\n",
        "    preds = valid_preds_df.groupby(\"recording_id\").max().drop(\"patch\", axis=1)\n",
        "    s = LWLRAP(\n",
        "        torch.tensor(np.stack(preds.values)), \n",
        "        torch.tensor(np.array(tp_labels)[valid_index])\n",
        "    )\n",
        "    auc_lst = [roc_auc_score(t, p) for p, t in zip(preds.values.T, np.array(tp_labels)[valid_index].T)]\n",
        "    a = sum(auc_lst)/len(auc_lst)\n",
        "    scores.append((s, a))\n",
        "    valid_preds_dfs.append(valid_preds_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t8DqCxihVm0q"
      },
      "source": [
        "LWLRAP(\n",
        "        torch.tensor(tp_result_df.groupby(\"recording_id\").max().drop(\"patch\", axis=1).loc[tp_fnames].values), \n",
        "        torch.tensor(np.array(tp_labels))\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-EzyCsjdS7wM"
      },
      "source": [
        "## Negative"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YNENCG6_WLVJ"
      },
      "source": [
        "fp_preds_dfs = []\n",
        "for fold in range(5):\n",
        "    print(f\"### {fold} ###\")\n",
        "    model.load_state_dict(torch.load(f\"{BEST_MODEL}/rfcxnet_f{fold}_best_score_model.bin\"))\n",
        "    model.eval()\n",
        "\n",
        "    fp_dataset = SpectrogramFromNpz(fp_fnames, \"train\")\n",
        "    lst = []\n",
        "    for idx, X in tqdm.tqdm_notebook(enumerate(fp_dataset), total=len(fp_dataset)):\n",
        "        preds = []\n",
        "        for patch, (h, t) in enumerate(slide_img_pos):\n",
        "            with torch.no_grad():\n",
        "                outputs = model(X[:,:,h:t].unsqueeze(0).to(device))\n",
        "            pred = outputs[\"clipwise_preds_att_ti\"].sigmoid().cpu().numpy()[0]\n",
        "            row = [fp_fnames[idx], patch] + pred.tolist()\n",
        "            lst.append(row)\n",
        "    fp_preds_df = pd.DataFrame(lst, columns=[\"recording_id\", \"patch\"]+ [f\"s{i}\" for i in range(24)])\n",
        "    fp_preds_dfs.append(fp_preds_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ktrpFfOSf7ak"
      },
      "source": [
        "lst = []\n",
        "for fold in range(5):\n",
        "    v = fp_preds_dfs[fold].values[:, 2:]\n",
        "    lst.append(v)\n",
        "\n",
        "fp_result_df = pd.DataFrame(np.hstack([fp_preds_dfs[0].values[:, :2], np.array(lst).mean(0)]),\n",
        "                                    columns=[\"recording_id\", \"patch\"]+ [f\"s{i}\" for i in range(24)])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DmdXsbJggLUk"
      },
      "source": [
        "## Merge"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y6EFGgVOgHVB"
      },
      "source": [
        "all_oof_result_df = pd.concat([tp_result_df, fp_result_df]).reset_index(drop=True)\n",
        "all_oof_result_df[\"org_recording_id\"] = all_oof_result_df[\"recording_id\"].map(lambda x: x.split(\"_\")[0])\n",
        "all_oof_result_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aBTUx5XigUwf"
      },
      "source": [
        "dfs = []\n",
        "for recording_id, df in all_oof_result_df.groupby(\"org_recording_id\"):\n",
        "    if len(df) > 8:\n",
        "        df = df[df[\"recording_id\"].map(lambda x: \"_posi\" in x)]\n",
        "    dfs.append(df)\n",
        "all_oof_result_df = pd.concat(dfs).reset_index(drop=True)\n",
        "all_oof_result_df[\"recording_id\"] = all_oof_result_df[\"org_recording_id\"]\n",
        "all_oof_result_df = all_oof_result_df.drop(\"org_recording_id\", axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p2nxNaT_gji8"
      },
      "source": [
        "all_oof_result_df.to_csv(\"oof_toda_v1.csv\", index=None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7jdWZE14S0sl"
      },
      "source": [
        "# Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w89NaC01Sf1N"
      },
      "source": [
        "sample_submission = pd.read_csv(f\"{DATA_ROOT}/sample_submission.csv\")\n",
        "test_fnames = sample_submission[\"recording_id\"].values\n",
        "test_datasets = SpectrogramFromNpz(test_fnames, \"test\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b1wC3PjkSf4L"
      },
      "source": [
        "test_dfs = []\n",
        "for fold in range(5):\n",
        "    print(f\"### {fold} ###\")\n",
        "    model.load_state_dict(torch.load(f\"{BEST_MODEL}/rfcxnet_f{fold}_best_score_model.bin\"))\n",
        "    model.eval()\n",
        "\n",
        "    lst = []\n",
        "    for idx, X in tqdm.tqdm_notebook(enumerate(test_datasets), total=len(test_datasets)):\n",
        "        preds = []\n",
        "        for patch, (h, t) in enumerate(slide_img_pos):\n",
        "            with torch.no_grad():\n",
        "                outputs = model(X[:,:,h:t].unsqueeze(0).to(device))\n",
        "            pred = outputs[\"clipwise_preds_att_ti\"].sigmoid().cpu().numpy()[0]\n",
        "            row = [test_fnames[idx], patch] + pred.tolist()\n",
        "            lst.append(row)\n",
        "    test_df = pd.DataFrame(lst, columns=[\"recording_id\", \"patch\"]+ [f\"s{i}\" for i in range(24)])\n",
        "    test_dfs.append(test_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oAXLkV83Sw2w"
      },
      "source": [
        "lst = []\n",
        "for fold in range(5):\n",
        "    v = test_dfs[fold].values[:, 2:]\n",
        "    lst.append(v)\n",
        "oof_test_pred_avg = pd.DataFrame(np.hstack([test_dfs[0].values[:, :2], np.array(lst).mean(0)]),\n",
        "                                    columns=[\"recording_id\", \"patch\"]+ [f\"s{i}\" for i in range(24)])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "peZL9TL6SzQ5"
      },
      "source": [
        "oof_test_pred_avg.to_csv(\"test_toda_v1.csv\", index=None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cfpZln5el-Qi"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}